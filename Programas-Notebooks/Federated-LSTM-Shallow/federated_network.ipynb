{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/reisdout/FederatedColab/blob/main/federated_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNTtfle5C1Xr",
    "outputId": "856fb13e-beca-46b8-c6f6-98a35b7b431c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive  \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "05Xx_xP4S3Om"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import RegressorMixin\n",
    "from tensorflow.python import training\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toe_0JZL3FTF"
   },
   "source": [
    "https://ai-pool.com/d/how-to-get-the-weights-of-keras-model-\n",
    "\n",
    "Keras has implemented some functions for getting or setting weights for every layer. \n",
    "\n",
    "    layer.get_weights(): returns the weights of the layer as a list of Numpy arrays.\n",
    "    layer.set_weights(weights): sets the weights of the layer from a list of Numpy arrays.\n",
    "\n",
    "Using these functions you can write a piece of code to get all layers' weights\n",
    "\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights() # list of numpy arrays\n",
    "\n",
    "Or you can get the weights right from the model\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# ...\n",
    "weights = model.get_weights() # returs a numpy list of weights\n",
    "\n",
    "Keras model also has get_weights() and set_weights(weights) functions like every layer has.\n",
    "\n",
    "If you need more take a look at this keras doc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/47183159/how-to-set-weights-in-keras-with-a-numpy-array\n",
    "\n",
    "The set_weights() method of keras accepts a list of numpy arrays, what you have passed to the method seems like a single array. The shape of this should be the same as the shape of the output of get_weights() on the same layer. Here's the code:\n",
    "```\n",
    "l=[]\n",
    "x=np.array() #weights\n",
    "y=np.array() #array of biases\n",
    "l.append(x)\n",
    "l.append(y)\n",
    "```\n",
    "\n",
    "loaded_model.layers[0].set_weights(l) #loaded_model.layer[0] being the layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2L_CN_jZMB0R"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  \n",
    "class Server_FederatedOMS:\n",
    "  \n",
    "  In the central server, we decide to use only the highest\n",
    "  accuracy holder model as the central server updated model, send it to the local\n",
    "  clients after the computation.\n",
    "\n",
    "\n",
    "\n",
    "  def ReceiveModelsFromClients(self, parIdCliente):\n",
    "    print(\"Recebido Modelo do Cliente 1\")\n",
    "  def Consolidar(self):\n",
    "    print(\"Consolidado todos os modelos\")\n",
    "  def FeedBackConsolidatedModel(self):\n",
    "    print (\"Modelos enviados\")\n",
    "\n",
    "  clients = ['Cliente1', 'Cliente2']\n",
    "\n",
    "\n",
    "class Server_FederatedBMA():\n",
    "\n",
    "owever, in the BMA technique, the central server receives\n",
    "four models with model accuracy performances from the local servers or clients.\n",
    "In the central server, we sort the model using their performances. Then we\n",
    "decide to use the two best models or half of the models based on performances.\n",
    "Then BMA technique loops through each model’s hidden layers and neurons to do\n",
    "the sum of the weights and average them accordingly.\n",
    "\n",
    "  def ReceiveModelsFromClients(self)\n",
    "  def Consolidar(self)\n",
    "  def FeedBackConsolidatedModel(self)\n",
    "\n",
    "    clients[] = ['Cliente1', 'Cliente2']\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, parCentralServer, parId):\n",
    "      self.id=parId\n",
    "      self.centralServer = parCentralServer\n",
    "      #self.centralServer.RegisterClient(self,self)\n",
    "\n",
    "\n",
    "'''\n",
    "class Client():\n",
    "\n",
    "\n",
    "\n",
    "    #resultadoTreinamento = np.eye(10)\n",
    "\n",
    "    def __init__(self,parId,parTraininPath, parTestPath, parPrevisionWindow):\n",
    "      self.id=parId\n",
    "      self.trainingPath=parTraininPath\n",
    "      self.testPath = parTestPath\n",
    "      self.T = parPrevisionWindow\n",
    "      #centralServer = Server_FederatedAMA()\n",
    "      #confusionMatrizModelClient = np.full((2,2), 1)\n",
    "      #confusionMatrizModelServer = np.full((2,2), 2)\n",
    "      self.currentConfusionMatriz =np.full((2,2), 0)\n",
    "      self.weightsClientModel = np.array([])\n",
    "      self.weightsServerModel = []\n",
    "      #self.base = pd.DataFrame()\n",
    "      #self.base_treinamento =  np.array([])\n",
    "      self.real_congestion_test = np.array([])\n",
    "      #self.test_vectors = []\n",
    "      #self.previsores = []\n",
    "      #self.real_congestion = []\n",
    "      #self.regressor = Sequential()\n",
    "      self.input_shape =0;\n",
    "      self.len_base_teste = 0;\n",
    "      #self.centralServer.RegisterClient(self,self)\n",
    "\n",
    "    def EvaluateServerModel(self):\n",
    "      print (\"Modelo do Servidor avaliado\")\n",
    "\n",
    "    def LoadTainingDataSet(self):\n",
    "      base = pd.read_csv(self.trainingPath)\n",
    "      base = base.dropna()\n",
    "      base_treinamento = base.iloc[:, [1,2,3,5]].values\n",
    "      previsores=[]\n",
    "      real_congestion = []\n",
    "      for i in range(self.T, base_treinamento.shape[0]): #base_treinamento.shape[0] número de linhas dos dados de treinamento\n",
    "        previsores.append(base_treinamento[i-self.T:i, 0:4])\n",
    "        real_congestion.append(base_treinamento[i, 3])#O resultado é do último cara\n",
    "      previsores, real_congestion = np.array(previsores), np.array(real_congestion)\n",
    "      self.input_shape = previsores.shape[1]\n",
    "      return previsores, real_congestion\n",
    "\n",
    "\n",
    "    def RefreshModel(self, parInitial=False): #Constroi na primeira vez e atualiza, a partir da avaliação do servidor cetral\n",
    "      #pensar melhor no critério\n",
    "      previsores,real_congestion = self.LoadTainingDataSet()\n",
    "            \n",
    "      if(parInitial):#tem que construir a rede do zero e treinar os pesos\n",
    "        regressor = Sequential()\n",
    "        regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
    "        regressor.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
    "        regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "        regressor.add(Dropout(0.3))\n",
    "        regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "        regressor.add(Dropout(0.3))\n",
    "        regressor.add(LSTM(units = 50))\n",
    "        regressor.add(Dropout(0.3))\n",
    "\n",
    "        '''\n",
    "        Segundo https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "        as saídas de cada unidade da LSTM e, portanto, a saída global é a dimenção do número de previsores, que, no nosso\n",
    "        caso, é 4. Daí esses 4 estão sendo levados em um softmax de tres neurônios, pois há tres categorias no final\"\n",
    "        ''' \n",
    "        regressor.add(Dense(units = 1, activation = 'sigmoid', name=\"client_\"+str(self.id)))\n",
    "        regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
    "        es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
    "        rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
    "        mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n",
    "                      save_best_only = True, verbose = 1)\n",
    "        regressor.fit(previsores, real_congestion, epochs = 100, batch_size = 32,\n",
    "                      callbacks = [es, rlr, mcp])\n",
    "        self.weightsClientModel = regressor.get_weights()\n",
    "      else:\n",
    "        if(self.ServerModelIsBetter()):\n",
    "          print(\"Pesos atualizados de acordo com o modelo do servidor\")\n",
    "        else:\n",
    "           print(\"Pesos Mantidos de acordo com o modelo do cliente\")\n",
    "\n",
    "    def GetMapedMatrix(self,parPrevisoes):\n",
    "      classe_teste2 = np.array([])\n",
    "      previsoes2 =  np.array([])\n",
    "\n",
    "      for i in range(0, self.len_base_teste):\n",
    "        if(self.real_congestion_test[i] < 0.3):\n",
    "          classe_teste2 = np.append(classe_teste2,0)\n",
    "        elif (self.real_congestion_test[i,0] >= 0.3 and self.real_congestion_test[i] < 0.75):\n",
    "          classe_teste2= np.append(classe_teste2,1)\n",
    "        else:\n",
    "          classe_teste2 = np.append(classe_teste2,2)\n",
    "\n",
    "      for i in range(0, len(parPrevisoes)):\n",
    "        if(parPrevisoes[i] < 0.3):\n",
    "          previsoes2= np.append(previsoes2,0)\n",
    "        elif (parPrevisoes[i] >= 0.3 and parPrevisoes[i] < 0.75):\n",
    "          previsoes2= np.append(previsoes2,1)\n",
    "        else:\n",
    "          previsoes2 = np.append(previsoes2,2)\n",
    "\n",
    "      return classe_teste2, previsoes2\n",
    "\n",
    "\n",
    "    def EvalueteServerModel(self, parServerModel):\n",
    "\n",
    "      test_vectors = self.LoadTestData()\n",
    "      previsoes = parServerModel.predict(test_vectors)\n",
    "      updated = False\n",
    "      '''\n",
    "      Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
    "      do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
    "      '''\n",
    "      classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes)\n",
    "      matriz = confusion_matrix(classe_teste2,previsoes2)\n",
    "      currentSum = 0\n",
    "      newSum = 0\n",
    "      if(self.currentConfusionMatriz.ndim > 1): # as vezes a rede pode errar ao ponto de dar só uma categoria, daí cai no else...\n",
    "        for i in range (0, len(self.currentConfusionMatriz)):\n",
    "            currentSum = currentSum + self.currentConfusionMatriz[i][i]\n",
    "      else:\n",
    "        currentSum = self.currentConfusionMatriz[i]\n",
    "      if(matriz.ndim > 1):\n",
    "        for i in range (0, len(matriz)):\n",
    "          newSum = newSum + matriz[i][i]\n",
    "      else:\n",
    "        newSum = matriz[i]\n",
    "      if(newSum > currentSum):\n",
    "        self.currentConfusionMatriz = np.array(matriz)\n",
    "        #self.regressor.set_weights(self.weightsServerModel)\n",
    "        self.weightsClientModel.clear()\n",
    "        for e in self.weightsServerModel:\n",
    "          self.weightsClientModel.append(e)\n",
    "        updated = True\n",
    "      print (\"Modelo do Servidor avaliado\")\n",
    "      return updated \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    def LoadTestData(self):\n",
    "      base = pd.read_csv(self.trainingPath)\n",
    "      base = base.dropna()\n",
    "      base_teste = pd.read_csv(self.testPath)\n",
    "      base_teste = base_teste.dropna()\n",
    "      self.real_congestion_test = base_teste.iloc[:, 5:6].values\n",
    "      frames = [base, base_teste]\n",
    "      base_completa = pd.concat(frames)\n",
    "      base_completa = base_completa.drop('#Ack', axis =1)\n",
    "      base_completa = base_completa.drop('cwnd (Bytes/1000)', axis =1)\n",
    "      base_completa = base_completa.drop('Network Situation', axis =1)\n",
    "      base_completa = base_completa.drop('AckArrival(ms)', axis =1)\n",
    "      base_completa = base_completa.drop('TSInsideAck(ms)', axis =1)\n",
    "      base_completa = base_completa.drop('RTTAck(ms)', axis =1)\n",
    "      entradas = base_completa[len(base_completa) - len(base_teste) - self.T:].values\n",
    "      #base_teste_features = base_teste.iloc[:, [1,2,3,6]].values\n",
    "      print(\"#############len(base_teste): \",len(base_teste))\n",
    "      self.len_base_teste = len(base_teste)\n",
    "      X_teste = []\n",
    "\n",
    "      for i in range(self.T, len(base_teste)+self.T): # para as duzentas previsoes, o mesmo tramanho do Teste.csv, ou seja 290-90\n",
    "        X_teste.append(entradas[i-self.T:i,0:4])\n",
    "\n",
    "\n",
    "      test_vectors = np.array(X_teste) # equivalente ao X_teste\n",
    "      return test_vectors\n",
    "    '''   \n",
    "    def RefreshConfusionClientMatrix(self):\n",
    "      #confrontar resultados\n",
    "      self.confusionMatrizModelClient = np.full((2,2),random.randint(0,9))\n",
    "\n",
    "    def RefreshConfusionServerMatrix(self):\n",
    "      #confrontar resultados\n",
    "      self.confusionMatrizModelServer = np.full((2,2),random.randint(0,9))\n",
    "    '''       \n",
    "    def ReceiveModelFromServer(self, parCandidateMatrix):\n",
    "      print(\"Cliente \", self.id, \" Recebido Modelo do Servidor\")\n",
    "      self.weightsServerModel.clear()\n",
    "      for e in parCandidateMatrix :\n",
    "        self.weightsServerModel.append(e)\n",
    "      \n",
    "    def SendModelToServer(self):\n",
    "      self.centralServ.ReceiveModelsFromClients(self.id)\n",
    "      print(\"Client\", self.id, \"Sending Model To Server\")\n",
    "    '''\n",
    "    def TreinarModelo(self):\n",
    "      print(\"Cliente \", self.id, \"treinando Modelo\")\n",
    "      time.sleep(random.randint(0,9))\n",
    "      self.RefreshConfusionClientMatrix()\n",
    "\n",
    "    '''\n",
    "    def GetPrevision(self): #evalueta indica que é uma avaliação do modelo recebido como parametro, no caso do servidor\n",
    "      test_vectors = self.LoadTestData()\n",
    "      regressor = Sequential()\n",
    "      regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
    "      regressor.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
    "      regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "      regressor.add(Dropout(0.3))\n",
    "      regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "      regressor.add(Dropout(0.3))\n",
    "      regressor.add(LSTM(units = 50))\n",
    "      regressor.add(Dropout(0.3))\n",
    "      regressor.add(Dense(units = 1, activation = 'sigmoid',name=\"client_eval_\"+str(self.id)))\n",
    "      regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
    "\n",
    "      regressor.set_weights(self.weightsClientModel)\n",
    "\n",
    "      previsoes = regressor.predict(test_vectors)\n",
    "      #previsoes = parNeuralModel.predict(self.test_vectors)\n",
    "     \n",
    "      '''\n",
    "      Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
    "      do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
    "      '''\n",
    "      #classe_teste2 = np.array([])\n",
    "      #previsoes2 =  np.array([])\n",
    "      classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes)\n",
    "      '''\n",
    "      for i in range(0, len(self.base_teste)):\n",
    "        if(self.real_congestion_test[i] < 0.3):\n",
    "          classe_teste2 = np.append(classe_teste2,0)\n",
    "        elif (self.real_congestion_test[i,0] >= 0.3 and self.real_congestion_test[i] < 0.75):\n",
    "          classe_teste2= np.append(classe_teste2,1)\n",
    "        else:\n",
    "          classe_teste2 = np.append(classe_teste2,2)\n",
    "\n",
    "      for i in range(0, len(previsoes)):\n",
    "        if(previsoes[i] < 0.3):\n",
    "          previsoes2= np.append(previsoes2,0)\n",
    "        elif (previsoes[i] >= 0.3 and previsoes[i] < 0.75):\n",
    "          previsoes2= np.append(previsoes2,1)\n",
    "        else:\n",
    "          previsoes2 = np.append(previsoes2,2)\n",
    "      '''\n",
    "      self.currentConfusionMatriz = confusion_matrix(classe_teste2,previsoes2)\n",
    "      return self.currentConfusionMatriz # Com a configuração corrente, essa é a matriz....\n",
    "        \n",
    "\n",
    "    def ServerModelIsBetter(self):\n",
    "        regressorServer = Sequential()\n",
    "        regressorServer.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
    "        regressorServer.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
    "        regressorServer.add(LSTM(units = 50, return_sequences = True))\n",
    "        regressorServer.add(Dropout(0.3))\n",
    "        regressorServer.add(LSTM(units = 50, return_sequences = True))\n",
    "        regressorServer.add(Dropout(0.3))\n",
    "        regressorServer.add(LSTM(units = 50))\n",
    "        regressorServer.add(Dropout(0.3))\n",
    "\n",
    "        '''\n",
    "        Segundo https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "        as saídas de cada unidade da LSTM e, portanto, a saída global é a dimenção do número de previsores, que, no nosso\n",
    "        caso, é 4. Daí esses 4 estão sendo levados em um softmax de tres neurônios, pois há tres categorias no final\"\n",
    "        ''' \n",
    "        regressorServer.add(Dense(units = 1, activation = 'sigmoid',name=\"client_eval_\"+str(self.id)))\n",
    "        regressorServer.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
    "        regressorServer.set_weights(self.weightsServerModel)\n",
    "        return self.EvalueteServerModel(regressorServer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Server_FederatedAMA():\n",
    "  '''\n",
    "  During the aggregation,\n",
    "  we first sum and average the neuron weights of each model. Then we store the\n",
    "  average value in the designated global model position. In the neural network\n",
    "  model, the same process is calculated for every neuron. After completing Al-\n",
    "  gorithm 2, the central server aggregated model is sent to all the clients for the\n",
    "  next learning phase\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    self.clients = []\n",
    "    self.ReceivedModel = [False,False,False]\n",
    "    self.consolidateWeightMatrix = []\n",
    "\n",
    "  def PrintRegistredClients(self):\n",
    "    print(\"Registred Clients\")\n",
    "    for x in self.clients:\n",
    "      print(\"Client \", x.id)\n",
    "  \n",
    "  def RegisterClient(self, parCliente):\n",
    "    self.clients.append(parCliente)\n",
    "    #print(\"Cliente \", parCliente.id, \" Regitrado com sucesso\")\n",
    "\n",
    "  '''\n",
    "  def ReceiveModelsFromClient(self, parId):\n",
    "   print(\"Recebido Modelos dos Cliente \", parId)    \n",
    "   self.ConsolideModels()\n",
    "\n",
    "  '''  \n",
    "    \n",
    "\n",
    "  def ConsolidateModels(self):\n",
    "\n",
    "    '''\n",
    "      #########################################################################################################################################\n",
    "      listaBase = [[\"amarelo\",\"verde\",\"preto\"], [\"azul\",\"abóbora\",\"marrom\"], [\"uva\",\"laranja\",\"branco\"]]\n",
    "      arrays_in_Layer=[]\n",
    "      lstTemp = []\n",
    "      lst_arrays_in_Layer = []\n",
    "      for layer in listaBase:\n",
    "          for arr in layer:\n",
    "              lstTemp.append(arr)\n",
    "          arrays_in_Layer = [i for i in lstTemp]\n",
    "          lst_arrays_in_Layer.append(arrays_in_Layer)\n",
    "          lstTemp.clear()\n",
    "      print (lst_arrays_in_Layer)\n",
    "      \n",
    "      \n",
    "      #uma inspiraçao\n",
    "      l=[]\n",
    "      x=np.array() #weights\n",
    "      y=np.array() #array of biases\n",
    "      l.append(x)\n",
    "      l.append(y)\n",
    "      loaded_model.layers[0].set_weights(l) #loaded_model.layer[0] being the layer\n",
    "  \n",
    "    '''\n",
    "    #client_layers = []\n",
    "\n",
    "    numberClients = len(self.clients)\n",
    "    #lstTemp = []\n",
    "    #arrays_in_Layer=[]\n",
    "    #lst_arrays_in_Layer = []\n",
    "    #lst_consolidated_arrays_in_layer = [] #as camadas, composta por arraysconsolidados\n",
    "    consolidated_arrays_in_layer = [] #arrays da camada\n",
    "    #consolidated_array = None\n",
    "    consolidated_model = []\n",
    "    clients_weighted_models = []\n",
    "    '''\n",
    "    #Cada weightsClientModel é uma lista de numpyarrays crua \"flatem\", isto é\n",
    "    se um modelo tem, por exemplo, 3 camadas e cada uma com dois arrays, o \n",
    "    weightsClientModel será uma lista de 6 numpy´s, com os dois primeiros vetores da \n",
    "    primeira camada no início, seguidos dos dois da segunta e, depois, os dois da terceira.\n",
    "    Nada de listas. É uma Listona de numpys\n",
    "    '''\n",
    "    for client in self.clients:\n",
    "        #print(client.weightsClientModel)\n",
    "        #input(\"pesos acima\")\n",
    "        clients_weighted_models.append(client.weightsClientModel)\n",
    "    \n",
    "    \n",
    "    #Criando a estrutura do Modelo\n",
    "    #for model in client_weighted_model:\n",
    "    '''\n",
    "    count_arrays=0\n",
    "    count_layers=0\n",
    "    for arr in clients_weighted_models[0]:\n",
    "       if(arr.shape[0]):\n",
    "          count_arrays+=1\n",
    "          consolidated_arrays_in_layer.append(np.full((2,2), 0))\n",
    "    input(f\"Quantidade de Arrays {count_arrays} do modelo\")\n",
    "        \n",
    "    #for i in range(0,len (clients_weighted_models)):\n",
    "    print(\"Shapes do modelo Consolidado\")\n",
    "    for j in range (0, len(consolidated_model)):\n",
    "        for k in range (0, len (consolidated_model[j])):\n",
    "            #print (f\"({i},j{j},k{k}\")\n",
    "            print(\"consolidated shape--> (\", consolidated_model[j][k].shape,\")\")\n",
    "            \n",
    "    input(\"final das shape\")\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    ###############Verificando as Shapes\n",
    "    \n",
    "    for i in range(0,len (clients_weighted_models)-1):\n",
    "        print(\"Verificando as shapes\")\n",
    "        #input(\"mais uma shape\")\n",
    "        for j in range (0, len(clients_weighted_models[i])):\n",
    "            for k in range (0, len (clients_weighted_models[i][j])):\n",
    "                \n",
    "                if(clients_weighted_models[i][j][k].shape != clients_weighted_models[i+1][j][k].shape):\n",
    "                        print(\"shapes incompativeis\")\n",
    "                        #exit(1)\n",
    "                       \n",
    "    \n",
    "    print(\"camadas cliente 0:\", len(clients_weighted_models[0][0]))\n",
    "    \n",
    "    print(\"camadas modelo consolidado: \", len(consolidated_model[0]))\n",
    "    '''\n",
    "    \n",
    "    for i in range(0,len (clients_weighted_models)):\n",
    "       for j in range (0, len(clients_weighted_models[i])):\n",
    "            if(i==0):\n",
    "                consolidated_model.append(clients_weighted_models[i][j])#alocando a lista com os pesos do primeiro modelo.\n",
    "            else:\n",
    "                consolidated_model[j] = consolidated_model[j] + clients_weighted_models[i][j]\n",
    "            if (i == numberClients - 1):\n",
    "                consolidated_model[j] = consolidated_model[j]/numberClients\n",
    "                \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for model in client_weighted_model:\n",
    "        count_client = count_client + 1    \n",
    "        for layer in model:\n",
    "            for arr in layer:\n",
    "                if(count_client==0):\n",
    "                    consolidated_array = arr\n",
    "                else:\n",
    "                    consolidated_array = consolidated_array + arr\n",
    "                if (count_client == numberClients - 1):\n",
    "                    consolidated_array = consolidated_array/numberClients\n",
    "                consolidated_arrays_in_layer.append(consolidated_array)\n",
    "            lst_consolidated_arrays_in_layer.append(consolidated_arrays_in_layer)\n",
    "    \n",
    "\n",
    "    #obtendo os numpy de cada layer\n",
    "    count_client=-1\n",
    "    for model in client_weighted_model:\n",
    "        count_client = count_client + 1    \n",
    "        for layer in model:\n",
    "            for arr in layer:\n",
    "                if(count_client==0):\n",
    "                    consolidated_array = arr\n",
    "                else:\n",
    "                    consolidated_array = consolidated_array + arr\n",
    "                if (count_client == numberClients - 1):\n",
    "                    consolidated_array = consolidated_array/numberClients\n",
    "                consolidated_arrays_in_layer.append(consolidated_array)\n",
    "            lst_consolidated_arrays_in_layer.append(consolidated_arrays_in_layer)\n",
    "            \n",
    "    self.consolidateWeightedMatrix = lst_consolidated_arrays_in_layer\n",
    "                \n",
    "              \n",
    "      arrays_in_Layer = [i for i in lstTemp]\n",
    "      lst_arrays_in_Layer.append(arrays_in_Layer)\n",
    "      lstTemp.clear()\n",
    "      \n",
    "    client_layers.append(lst_arrays_in_Layer)\n",
    "    \n",
    "    #consolidando os pesos\n",
    "    cout_client=-1\n",
    "    for client_layer in client_layers:\n",
    "      cont_client = count_client+1  \n",
    "      for array_list in client_layer:\n",
    "        for array in array_list:\n",
    "            if(count_client==0):\n",
    "                consolidated_array = array\n",
    "            else:\n",
    "                consolidated_array = consolidated_array + array\n",
    "                \n",
    "        consolidated_arrays_in_layer.append(consolidated_array)\n",
    "      \n",
    "    \n",
    "    for i in range (1, numberClients):\n",
    "      self.consolidateWeightedMatrix = self.consolidateWeightedMatrix + self.clients[i].weightsClientModel\n",
    "    self.consolidateWeightedMatrix = self.consolidateWeightedMatrix/numberClients\n",
    "    print(\"Models were consolidated\")\n",
    "    \n",
    "    '''\n",
    "    #self.consolidateWeightMatrix = consolidated_model # cuidado com isso!\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    for e in consolidated_model:\n",
    "        self.consolidateWeightMatrix.append(e)\n",
    "\n",
    "    \n",
    "    print(\"Amostra Peso Clientes:\")\n",
    "    for client in self.clients:\n",
    "      print(\"============================\")\n",
    "      print(client.weightsClientModel[0][0][0:4])\n",
    "    print(\"Amostra Peso Consolidado: \")\n",
    "    print(self.consolidateWeightMatrix[0][0][0:4])\n",
    "    \n",
    "\n",
    "  def FeedBackConsolidatedModel(self):\n",
    "    for x in self.clients:\n",
    "      x.ReceiveModelFromServer(self.consolidateWeightMatrix)\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    print(\"Feedbacks Enviados e descartados\")\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM23KmU7_urd"
   },
   "source": [
    "Separando Lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RoXYDyj85uB",
    "outputId": "b339d904-b55e-4f35-b248-530e296e59ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['amarelo', 'verde', 'preto'], ['azul', 'abóbora', 'marrom'], ['uva', 'laranja', 'branco']]\n"
     ]
    }
   ],
   "source": [
    "listaBase = [[\"amarelo\",\"verde\",\"preto\"], [\"azul\",\"abóbora\",\"marrom\"], [\"uva\",\"laranja\",\"branco\"]]\n",
    "arrays_in_Layer=[]\n",
    "lstTemp = []\n",
    "lst_arrays_in_Layer = []\n",
    "for layer in listaBase:\n",
    "  for arr in layer:\n",
    "    lstTemp.append(arr)\n",
    "  arrays_in_Layer = [i for i in lstTemp]\n",
    "  lst_arrays_in_Layer.append(arrays_in_Layer)\n",
    "  lstTemp.clear()\n",
    "print (lst_arrays_in_Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "226DTudwM1mO",
    "outputId": "1ed7f6b4-6e9e-4152-a0f0-fdc1a3d470db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0884 - mean_absolute_error: 0.2207\n",
      "Epoch 1: loss improved from inf to 0.08840, saving model to pesos.h5\n",
      "47/47 [==============================] - 24s 270ms/step - loss: 0.0884 - mean_absolute_error: 0.2207 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0504 - mean_absolute_error: 0.1395\n",
      "Epoch 2: loss improved from 0.08840 to 0.05040, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 244ms/step - loss: 0.0504 - mean_absolute_error: 0.1395 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.0972\n",
      "Epoch 3: loss improved from 0.05040 to 0.03342, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.0334 - mean_absolute_error: 0.0972 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.0875\n",
      "Epoch 4: loss improved from 0.03342 to 0.02929, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 232ms/step - loss: 0.0293 - mean_absolute_error: 0.0875 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0250 - mean_absolute_error: 0.0743\n",
      "Epoch 5: loss improved from 0.02929 to 0.02500, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 240ms/step - loss: 0.0250 - mean_absolute_error: 0.0743 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.0850\n",
      "Epoch 6: loss did not improve from 0.02500\n",
      "47/47 [==============================] - 11s 241ms/step - loss: 0.0253 - mean_absolute_error: 0.0850 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.0680\n",
      "Epoch 7: loss improved from 0.02500 to 0.02002, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 243ms/step - loss: 0.0200 - mean_absolute_error: 0.0680 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0191 - mean_absolute_error: 0.0678\n",
      "Epoch 8: loss improved from 0.02002 to 0.01915, saving model to pesos.h5\n",
      "47/47 [==============================] - 10s 220ms/step - loss: 0.0191 - mean_absolute_error: 0.0678 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.0602\n",
      "Epoch 9: loss improved from 0.01915 to 0.01723, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 228ms/step - loss: 0.0172 - mean_absolute_error: 0.0602 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0135 - mean_absolute_error: 0.0526\n",
      "Epoch 10: loss improved from 0.01723 to 0.01351, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 246ms/step - loss: 0.0135 - mean_absolute_error: 0.0526 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0131 - mean_absolute_error: 0.0508\n",
      "Epoch 11: loss improved from 0.01351 to 0.01312, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0131 - mean_absolute_error: 0.0508 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0514\n",
      "Epoch 12: loss did not improve from 0.01312\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0138 - mean_absolute_error: 0.0514 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0167 - mean_absolute_error: 0.0592\n",
      "Epoch 13: loss did not improve from 0.01312\n",
      "47/47 [==============================] - 15s 324ms/step - loss: 0.0167 - mean_absolute_error: 0.0592 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0512\n",
      "Epoch 14: loss improved from 0.01312 to 0.01265, saving model to pesos.h5\n",
      "47/47 [==============================] - 15s 312ms/step - loss: 0.0127 - mean_absolute_error: 0.0512 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.0492\n",
      "Epoch 15: loss improved from 0.01265 to 0.01231, saving model to pesos.h5\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 0.0123 - mean_absolute_error: 0.0492 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0105 - mean_absolute_error: 0.0465\n",
      "Epoch 16: loss improved from 0.01231 to 0.01052, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 234ms/step - loss: 0.0105 - mean_absolute_error: 0.0465 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0113 - mean_absolute_error: 0.0471\n",
      "Epoch 17: loss did not improve from 0.01052\n",
      "47/47 [==============================] - 10s 217ms/step - loss: 0.0113 - mean_absolute_error: 0.0471 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0464\n",
      "Epoch 18: loss did not improve from 0.01052\n",
      "47/47 [==============================] - 11s 244ms/step - loss: 0.0108 - mean_absolute_error: 0.0464 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0118 - mean_absolute_error: 0.0453\n",
      "Epoch 19: loss did not improve from 0.01052\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0118 - mean_absolute_error: 0.0453 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0110 - mean_absolute_error: 0.0442\n",
      "Epoch 20: loss did not improve from 0.01052\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0110 - mean_absolute_error: 0.0442 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0455\n",
      "Epoch 21: loss improved from 0.01052 to 0.01035, saving model to pesos.h5\n",
      "47/47 [==============================] - 10s 221ms/step - loss: 0.0104 - mean_absolute_error: 0.0455 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.0402\n",
      "Epoch 22: loss improved from 0.01035 to 0.00860, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 233ms/step - loss: 0.0086 - mean_absolute_error: 0.0402 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0430\n",
      "Epoch 23: loss did not improve from 0.00860\n",
      "47/47 [==============================] - 11s 245ms/step - loss: 0.0098 - mean_absolute_error: 0.0430 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0115 - mean_absolute_error: 0.0462\n",
      "Epoch 24: loss did not improve from 0.00860\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0115 - mean_absolute_error: 0.0462 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0099 - mean_absolute_error: 0.0434\n",
      "Epoch 25: loss did not improve from 0.00860\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0099 - mean_absolute_error: 0.0434 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0364\n",
      "Epoch 26: loss improved from 0.00860 to 0.00742, saving model to pesos.h5\n",
      "47/47 [==============================] - 10s 211ms/step - loss: 0.0074 - mean_absolute_error: 0.0364 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0075 - mean_absolute_error: 0.0367\n",
      "Epoch 27: loss did not improve from 0.00742\n",
      "47/47 [==============================] - 12s 244ms/step - loss: 0.0075 - mean_absolute_error: 0.0367 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0369\n",
      "Epoch 28: loss did not improve from 0.00742\n",
      "47/47 [==============================] - 12s 246ms/step - loss: 0.0076 - mean_absolute_error: 0.0369 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.0388\n",
      "Epoch 29: loss did not improve from 0.00742\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0089 - mean_absolute_error: 0.0388 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0073 - mean_absolute_error: 0.0361\n",
      "Epoch 30: loss improved from 0.00742 to 0.00732, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 245ms/step - loss: 0.0073 - mean_absolute_error: 0.0361 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_error: 0.0362\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00732\n",
      "47/47 [==============================] - 10s 218ms/step - loss: 0.0074 - mean_absolute_error: 0.0362 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0304\n",
      "Epoch 32: loss improved from 0.00732 to 0.00539, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0054 - mean_absolute_error: 0.0304 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0290\n",
      "Epoch 33: loss improved from 0.00539 to 0.00511, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0051 - mean_absolute_error: 0.0290 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0046 - mean_absolute_error: 0.0273\n",
      "Epoch 34: loss improved from 0.00511 to 0.00462, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.0046 - mean_absolute_error: 0.0273 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0262\n",
      "Epoch 35: loss improved from 0.00462 to 0.00412, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 241ms/step - loss: 0.0041 - mean_absolute_error: 0.0262 - lr: 2.0000e-04\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0271\n",
      "Epoch 36: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 10s 217ms/step - loss: 0.0043 - mean_absolute_error: 0.0271 - lr: 2.0000e-04\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0272\n",
      "Epoch 37: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0048 - mean_absolute_error: 0.0272 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0278\n",
      "Epoch 38: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0050 - mean_absolute_error: 0.0278 - lr: 2.0000e-04\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0255\n",
      "Epoch 39: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.0042 - mean_absolute_error: 0.0255 - lr: 2.0000e-04\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0259\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 11s 245ms/step - loss: 0.0043 - mean_absolute_error: 0.0259 - lr: 2.0000e-04\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0256\n",
      "Epoch 41: loss did not improve from 0.00412\n",
      "47/47 [==============================] - 11s 221ms/step - loss: 0.0043 - mean_absolute_error: 0.0256 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0259\n",
      "Epoch 42: loss improved from 0.00412 to 0.00397, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.0040 - mean_absolute_error: 0.0259 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0259\n",
      "Epoch 43: loss did not improve from 0.00397\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0041 - mean_absolute_error: 0.0259 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0257\n",
      "Epoch 44: loss improved from 0.00397 to 0.00396, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0040 - mean_absolute_error: 0.0257 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0247\n",
      "Epoch 45: loss improved from 0.00396 to 0.00385, saving model to pesos.h5\n",
      "47/47 [==============================] - 24s 513ms/step - loss: 0.0038 - mean_absolute_error: 0.0247 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0254\n",
      "Epoch 46: loss did not improve from 0.00385\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0043 - mean_absolute_error: 0.0254 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0257\n",
      "Epoch 47: loss did not improve from 0.00385\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0042 - mean_absolute_error: 0.0257 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0249\n",
      "Epoch 48: loss did not improve from 0.00385\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0040 - mean_absolute_error: 0.0249 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0257\n",
      "Epoch 49: loss did not improve from 0.00385\n",
      "47/47 [==============================] - 11s 236ms/step - loss: 0.0041 - mean_absolute_error: 0.0257 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0245\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 50: loss improved from 0.00385 to 0.00383, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 233ms/step - loss: 0.0038 - mean_absolute_error: 0.0245 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0245\n",
      "Epoch 51: loss improved from 0.00383 to 0.00373, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.0037 - mean_absolute_error: 0.0245 - lr: 8.0000e-06\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0253\n",
      "Epoch 52: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0042 - mean_absolute_error: 0.0253 - lr: 8.0000e-06\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0258\n",
      "Epoch 53: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 14s 294ms/step - loss: 0.0039 - mean_absolute_error: 0.0258 - lr: 8.0000e-06\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0254\n",
      "Epoch 54: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 24s 507ms/step - loss: 0.0041 - mean_absolute_error: 0.0254 - lr: 8.0000e-06\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0263\n",
      "Epoch 55: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 15s 314ms/step - loss: 0.0044 - mean_absolute_error: 0.0263 - lr: 8.0000e-06\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0253\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 13s 268ms/step - loss: 0.0042 - mean_absolute_error: 0.0253 - lr: 8.0000e-06\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0257\n",
      "Epoch 57: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 12s 244ms/step - loss: 0.0041 - mean_absolute_error: 0.0257 - lr: 1.6000e-06\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0258\n",
      "Epoch 58: loss did not improve from 0.00373\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0043 - mean_absolute_error: 0.0258 - lr: 1.6000e-06\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0245\n",
      "Epoch 59: loss improved from 0.00373 to 0.00371, saving model to pesos.h5\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.0037 - mean_absolute_error: 0.0245 - lr: 1.6000e-06\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0266\n",
      "Epoch 60: loss did not improve from 0.00371\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.0044 - mean_absolute_error: 0.0266 - lr: 1.6000e-06\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0240\n",
      "Epoch 61: loss improved from 0.00371 to 0.00338, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 240ms/step - loss: 0.0034 - mean_absolute_error: 0.0240 - lr: 1.6000e-06\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0230\n",
      "Epoch 62: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.0034 - mean_absolute_error: 0.0230 - lr: 1.6000e-06\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0249\n",
      "Epoch 63: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0037 - mean_absolute_error: 0.0249 - lr: 1.6000e-06\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0249\n",
      "Epoch 64: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0040 - mean_absolute_error: 0.0249 - lr: 1.6000e-06\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0248\n",
      "Epoch 65: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.0039 - mean_absolute_error: 0.0248 - lr: 1.6000e-06\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0250\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.0038 - mean_absolute_error: 0.0250 - lr: 1.6000e-06\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0243\n",
      "Epoch 67: loss did not improve from 0.00338\n",
      "47/47 [==============================] - 11s 238ms/step - loss: 0.0036 - mean_absolute_error: 0.0243 - lr: 3.2000e-07\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0233\n",
      "Epoch 68: loss improved from 0.00338 to 0.00329, saving model to pesos.h5\n",
      "47/47 [==============================] - 11s 228ms/step - loss: 0.0033 - mean_absolute_error: 0.0233 - lr: 3.2000e-07\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0046 - mean_absolute_error: 0.0260\n",
      "Epoch 69: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.0046 - mean_absolute_error: 0.0260 - lr: 3.2000e-07\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0259\n",
      "Epoch 70: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0048 - mean_absolute_error: 0.0259 - lr: 3.2000e-07\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0247\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0037 - mean_absolute_error: 0.0247 - lr: 3.2000e-07\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0248\n",
      "Epoch 72: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 266ms/step - loss: 0.0039 - mean_absolute_error: 0.0248 - lr: 6.4000e-08\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0262\n",
      "Epoch 73: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 11s 227ms/step - loss: 0.0043 - mean_absolute_error: 0.0262 - lr: 6.4000e-08\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0247\n",
      "Epoch 74: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 11s 240ms/step - loss: 0.0041 - mean_absolute_error: 0.0247 - lr: 6.4000e-08\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0242\n",
      "Epoch 75: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0036 - mean_absolute_error: 0.0242 - lr: 6.4000e-08\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0247\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.0041 - mean_absolute_error: 0.0247 - lr: 6.4000e-08\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0250\n",
      "Epoch 77: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0038 - mean_absolute_error: 0.0250 - lr: 1.2800e-08\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0243\n",
      "Epoch 78: loss did not improve from 0.00329\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0035 - mean_absolute_error: 0.0243 - lr: 1.2800e-08\n",
      "Epoch 78: early stopping\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.1615\n",
      "Epoch 1: loss improved from inf to 0.06743, saving model to pesos.h5\n",
      "50/50 [==============================] - 21s 228ms/step - loss: 0.0674 - mean_absolute_error: 0.1615 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1032\n",
      "Epoch 2: loss improved from 0.06743 to 0.03978, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0398 - mean_absolute_error: 0.1032 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.0902\n",
      "Epoch 3: loss improved from 0.03978 to 0.03090, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.0309 - mean_absolute_error: 0.0902 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.0761\n",
      "Epoch 4: loss improved from 0.03090 to 0.02708, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0271 - mean_absolute_error: 0.0761 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.0772\n",
      "Epoch 5: loss improved from 0.02708 to 0.02485, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0249 - mean_absolute_error: 0.0772 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.0624\n",
      "Epoch 6: loss improved from 0.02485 to 0.02264, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 0.0226 - mean_absolute_error: 0.0624 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0710\n",
      "Epoch 7: loss did not improve from 0.02264\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 0.0255 - mean_absolute_error: 0.0710 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.0656\n",
      "Epoch 8: loss did not improve from 0.02264\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.0232 - mean_absolute_error: 0.0656 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.0608\n",
      "Epoch 9: loss did not improve from 0.02264\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0239 - mean_absolute_error: 0.0608 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.0623\n",
      "Epoch 10: loss improved from 0.02264 to 0.02025, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0203 - mean_absolute_error: 0.0623 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.0577\n",
      "Epoch 11: loss did not improve from 0.02025\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0217 - mean_absolute_error: 0.0577 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0216 - mean_absolute_error: 0.0582\n",
      "Epoch 12: loss did not improve from 0.02025\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 0.0216 - mean_absolute_error: 0.0582 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.0511\n",
      "Epoch 13: loss did not improve from 0.02025\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 0.0235 - mean_absolute_error: 0.0511 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0699\n",
      "Epoch 14: loss did not improve from 0.02025\n",
      "50/50 [==============================] - 11s 219ms/step - loss: 0.0247 - mean_absolute_error: 0.0699 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.0554\n",
      "Epoch 15: loss improved from 0.02025 to 0.01871, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 0.0187 - mean_absolute_error: 0.0554 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.0583\n",
      "Epoch 16: loss improved from 0.01871 to 0.01828, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0183 - mean_absolute_error: 0.0583 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.0467\n",
      "Epoch 17: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.0235 - mean_absolute_error: 0.0467 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.0486\n",
      "Epoch 18: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0264 - mean_absolute_error: 0.0486 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.0575\n",
      "Epoch 19: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0255 - mean_absolute_error: 0.0575 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0263 - mean_absolute_error: 0.0716\n",
      "Epoch 20: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0263 - mean_absolute_error: 0.0716 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0258 - mean_absolute_error: 0.0687\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0258 - mean_absolute_error: 0.0687 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.0672\n",
      "Epoch 22: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 12s 230ms/step - loss: 0.0247 - mean_absolute_error: 0.0672 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.0698\n",
      "Epoch 23: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0243 - mean_absolute_error: 0.0698 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0221 - mean_absolute_error: 0.0699\n",
      "Epoch 24: loss did not improve from 0.01828\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0221 - mean_absolute_error: 0.0699 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0170 - mean_absolute_error: 0.0615\n",
      "Epoch 25: loss improved from 0.01828 to 0.01697, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0170 - mean_absolute_error: 0.0615 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0141 - mean_absolute_error: 0.0527\n",
      "Epoch 26: loss improved from 0.01697 to 0.01411, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0141 - mean_absolute_error: 0.0527 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0136 - mean_absolute_error: 0.0492\n",
      "Epoch 27: loss improved from 0.01411 to 0.01362, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0136 - mean_absolute_error: 0.0492 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0476\n",
      "Epoch 28: loss did not improve from 0.01362\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0138 - mean_absolute_error: 0.0476 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0128 - mean_absolute_error: 0.0438\n",
      "Epoch 29: loss improved from 0.01362 to 0.01283, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0128 - mean_absolute_error: 0.0438 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0106 - mean_absolute_error: 0.0389\n",
      "Epoch 30: loss improved from 0.01283 to 0.01063, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 0.0106 - mean_absolute_error: 0.0389 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.0354\n",
      "Epoch 31: loss improved from 0.01063 to 0.00924, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0092 - mean_absolute_error: 0.0354 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0318\n",
      "Epoch 32: loss improved from 0.00924 to 0.00819, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0082 - mean_absolute_error: 0.0318 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0319\n",
      "Epoch 33: loss did not improve from 0.00819\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0083 - mean_absolute_error: 0.0319 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.0298\n",
      "Epoch 34: loss did not improve from 0.00819\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0089 - mean_absolute_error: 0.0298 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0279\n",
      "Epoch 35: loss improved from 0.00819 to 0.00787, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0079 - mean_absolute_error: 0.0279 - lr: 2.0000e-04\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0275\n",
      "Epoch 36: loss improved from 0.00787 to 0.00650, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0065 - mean_absolute_error: 0.0275 - lr: 2.0000e-04\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0064 - mean_absolute_error: 0.0271\n",
      "Epoch 37: loss improved from 0.00650 to 0.00637, saving model to pesos.h5\n",
      "50/50 [==============================] - 12s 238ms/step - loss: 0.0064 - mean_absolute_error: 0.0271 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0066 - mean_absolute_error: 0.0263\n",
      "Epoch 38: loss did not improve from 0.00637\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.0066 - mean_absolute_error: 0.0263 - lr: 2.0000e-04\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0280\n",
      "Epoch 39: loss did not improve from 0.00637\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0072 - mean_absolute_error: 0.0280 - lr: 2.0000e-04\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.0293\n",
      "Epoch 40: loss did not improve from 0.00637\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0079 - mean_absolute_error: 0.0293 - lr: 2.0000e-04\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_error: 0.0262\n",
      "Epoch 41: loss improved from 0.00637 to 0.00607, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0061 - mean_absolute_error: 0.0262 - lr: 2.0000e-04\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0235\n",
      "Epoch 42: loss improved from 0.00607 to 0.00508, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0051 - mean_absolute_error: 0.0235 - lr: 2.0000e-04\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0058 - mean_absolute_error: 0.0238\n",
      "Epoch 43: loss did not improve from 0.00508\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0058 - mean_absolute_error: 0.0238 - lr: 2.0000e-04\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0236\n",
      "Epoch 44: loss did not improve from 0.00508\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.0057 - mean_absolute_error: 0.0236 - lr: 2.0000e-04\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0244\n",
      "Epoch 45: loss did not improve from 0.00508\n",
      "50/50 [==============================] - 12s 235ms/step - loss: 0.0057 - mean_absolute_error: 0.0244 - lr: 2.0000e-04\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0250\n",
      "Epoch 46: loss did not improve from 0.00508\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.0059 - mean_absolute_error: 0.0250 - lr: 2.0000e-04\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0228\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00508\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0051 - mean_absolute_error: 0.0228 - lr: 2.0000e-04\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0219\n",
      "Epoch 48: loss improved from 0.00508 to 0.00485, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0049 - mean_absolute_error: 0.0219 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0225\n",
      "Epoch 49: loss did not improve from 0.00485\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0052 - mean_absolute_error: 0.0225 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0228\n",
      "Epoch 50: loss did not improve from 0.00485\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0057 - mean_absolute_error: 0.0228 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0215\n",
      "Epoch 51: loss improved from 0.00485 to 0.00465, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0047 - mean_absolute_error: 0.0215 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0224\n",
      "Epoch 52: loss did not improve from 0.00465\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0050 - mean_absolute_error: 0.0224 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0206\n",
      "Epoch 53: loss improved from 0.00465 to 0.00434, saving model to pesos.h5\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0043 - mean_absolute_error: 0.0206 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0214\n",
      "Epoch 54: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 12s 237ms/step - loss: 0.0049 - mean_absolute_error: 0.0214 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0220\n",
      "Epoch 55: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 0.0052 - mean_absolute_error: 0.0220 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0221\n",
      "Epoch 56: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0050 - mean_absolute_error: 0.0221 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0216\n",
      "Epoch 57: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0047 - mean_absolute_error: 0.0216 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0212\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0047 - mean_absolute_error: 0.0212 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0225\n",
      "Epoch 59: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0054 - mean_absolute_error: 0.0225 - lr: 8.0000e-06\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0053 - mean_absolute_error: 0.0222\n",
      "Epoch 60: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0053 - mean_absolute_error: 0.0222 - lr: 8.0000e-06\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0217\n",
      "Epoch 61: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0048 - mean_absolute_error: 0.0217 - lr: 8.0000e-06\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0223\n",
      "Epoch 62: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 0.0054 - mean_absolute_error: 0.0223 - lr: 8.0000e-06\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_error: 0.0214\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00434\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.0049 - mean_absolute_error: 0.0214 - lr: 8.0000e-06\n",
      "Epoch 63: early stopping\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0387 - mean_absolute_error: 0.0945\n",
      "Epoch 1: loss improved from inf to 0.03872, saving model to pesos.h5\n",
      "94/94 [==============================] - 33s 253ms/step - loss: 0.0387 - mean_absolute_error: 0.0945 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0231 - mean_absolute_error: 0.0626\n",
      "Epoch 2: loss improved from 0.03872 to 0.02305, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 250ms/step - loss: 0.0231 - mean_absolute_error: 0.0626 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0192 - mean_absolute_error: 0.0518\n",
      "Epoch 3: loss improved from 0.02305 to 0.01922, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 247ms/step - loss: 0.0192 - mean_absolute_error: 0.0518 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0177 - mean_absolute_error: 0.0486\n",
      "Epoch 4: loss improved from 0.01922 to 0.01772, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 255ms/step - loss: 0.0177 - mean_absolute_error: 0.0486 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0168 - mean_absolute_error: 0.0473\n",
      "Epoch 5: loss improved from 0.01772 to 0.01677, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 253ms/step - loss: 0.0168 - mean_absolute_error: 0.0473 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.0428\n",
      "Epoch 6: loss improved from 0.01677 to 0.01617, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 247ms/step - loss: 0.0162 - mean_absolute_error: 0.0428 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0173 - mean_absolute_error: 0.0456\n",
      "Epoch 7: loss did not improve from 0.01617\n",
      "94/94 [==============================] - 24s 257ms/step - loss: 0.0173 - mean_absolute_error: 0.0456 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0165 - mean_absolute_error: 0.0459\n",
      "Epoch 8: loss did not improve from 0.01617\n",
      "94/94 [==============================] - 23s 244ms/step - loss: 0.0165 - mean_absolute_error: 0.0459 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0441\n",
      "Epoch 9: loss improved from 0.01617 to 0.01598, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 250ms/step - loss: 0.0160 - mean_absolute_error: 0.0441 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.0465\n",
      "Epoch 10: loss did not improve from 0.01598\n",
      "94/94 [==============================] - 24s 256ms/step - loss: 0.0160 - mean_absolute_error: 0.0465 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0433\n",
      "Epoch 11: loss improved from 0.01598 to 0.01504, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 240ms/step - loss: 0.0150 - mean_absolute_error: 0.0433 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0128 - mean_absolute_error: 0.0390\n",
      "Epoch 12: loss improved from 0.01504 to 0.01279, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 259ms/step - loss: 0.0128 - mean_absolute_error: 0.0390 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0392\n",
      "Epoch 13: loss did not improve from 0.01279\n",
      "94/94 [==============================] - 24s 257ms/step - loss: 0.0145 - mean_absolute_error: 0.0392 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0103 - mean_absolute_error: 0.0334\n",
      "Epoch 14: loss improved from 0.01279 to 0.01033, saving model to pesos.h5\n",
      "94/94 [==============================] - 22s 239ms/step - loss: 0.0103 - mean_absolute_error: 0.0334 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.0283\n",
      "Epoch 15: loss improved from 0.01033 to 0.00780, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 256ms/step - loss: 0.0078 - mean_absolute_error: 0.0283 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.0275\n",
      "Epoch 16: loss did not improve from 0.00780\n",
      "94/94 [==============================] - 24s 256ms/step - loss: 0.0080 - mean_absolute_error: 0.0275 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.0268\n",
      "Epoch 17: loss did not improve from 0.00780\n",
      "94/94 [==============================] - 23s 240ms/step - loss: 0.0083 - mean_absolute_error: 0.0268 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.0262\n",
      "Epoch 18: loss did not improve from 0.00780\n",
      "94/94 [==============================] - 24s 257ms/step - loss: 0.0096 - mean_absolute_error: 0.0262 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0121 - mean_absolute_error: 0.0334\n",
      "Epoch 19: loss did not improve from 0.00780\n",
      "94/94 [==============================] - 24s 256ms/step - loss: 0.0121 - mean_absolute_error: 0.0334 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0070 - mean_absolute_error: 0.0264\n",
      "Epoch 20: loss improved from 0.00780 to 0.00703, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 241ms/step - loss: 0.0070 - mean_absolute_error: 0.0264 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0204\n",
      "Epoch 21: loss improved from 0.00703 to 0.00520, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 261ms/step - loss: 0.0052 - mean_absolute_error: 0.0204 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0098 - mean_absolute_error: 0.0299\n",
      "Epoch 22: loss did not improve from 0.00520\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0098 - mean_absolute_error: 0.0299 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0058 - mean_absolute_error: 0.0229\n",
      "Epoch 23: loss did not improve from 0.00520\n",
      "94/94 [==============================] - 23s 244ms/step - loss: 0.0058 - mean_absolute_error: 0.0229 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0068 - mean_absolute_error: 0.0235\n",
      "Epoch 24: loss did not improve from 0.00520\n",
      "94/94 [==============================] - 24s 259ms/step - loss: 0.0068 - mean_absolute_error: 0.0235 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0227\n",
      "Epoch 25: loss did not improve from 0.00520\n",
      "94/94 [==============================] - 24s 260ms/step - loss: 0.0057 - mean_absolute_error: 0.0227 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0071 - mean_absolute_error: 0.0256\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00520\n",
      "94/94 [==============================] - 23s 242ms/step - loss: 0.0071 - mean_absolute_error: 0.0256 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0211\n",
      "Epoch 27: loss improved from 0.00520 to 0.00507, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 261ms/step - loss: 0.0051 - mean_absolute_error: 0.0211 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0165\n",
      "Epoch 28: loss improved from 0.00507 to 0.00369, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 260ms/step - loss: 0.0037 - mean_absolute_error: 0.0165 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0166\n",
      "Epoch 29: loss did not improve from 0.00369\n",
      "94/94 [==============================] - 23s 243ms/step - loss: 0.0039 - mean_absolute_error: 0.0166 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0159\n",
      "Epoch 30: loss improved from 0.00369 to 0.00366, saving model to pesos.h5\n",
      "94/94 [==============================] - 25s 265ms/step - loss: 0.0037 - mean_absolute_error: 0.0159 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0149\n",
      "Epoch 31: loss improved from 0.00366 to 0.00331, saving model to pesos.h5\n",
      "94/94 [==============================] - 25s 261ms/step - loss: 0.0033 - mean_absolute_error: 0.0149 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0137\n",
      "Epoch 32: loss improved from 0.00331 to 0.00284, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 243ms/step - loss: 0.0028 - mean_absolute_error: 0.0137 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0137\n",
      "Epoch 33: loss did not improve from 0.00284\n",
      "94/94 [==============================] - 25s 260ms/step - loss: 0.0032 - mean_absolute_error: 0.0137 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0146\n",
      "Epoch 34: loss did not improve from 0.00284\n",
      "94/94 [==============================] - 24s 260ms/step - loss: 0.0029 - mean_absolute_error: 0.0146 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0135\n",
      "Epoch 35: loss improved from 0.00284 to 0.00284, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0028 - mean_absolute_error: 0.0135 - lr: 2.0000e-04\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0141\n",
      "Epoch 36: loss improved from 0.00284 to 0.00283, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 256ms/step - loss: 0.0028 - mean_absolute_error: 0.0141 - lr: 2.0000e-04\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0141\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00283\n",
      "94/94 [==============================] - 24s 259ms/step - loss: 0.0031 - mean_absolute_error: 0.0141 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0138\n",
      "Epoch 38: loss improved from 0.00283 to 0.00275, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 249ms/step - loss: 0.0028 - mean_absolute_error: 0.0138 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0130\n",
      "Epoch 39: loss improved from 0.00275 to 0.00245, saving model to pesos.h5\n",
      "94/94 [==============================] - 24s 252ms/step - loss: 0.0024 - mean_absolute_error: 0.0130 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0139\n",
      "Epoch 40: loss did not improve from 0.00245\n",
      "94/94 [==============================] - 24s 259ms/step - loss: 0.0025 - mean_absolute_error: 0.0139 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0134\n",
      "Epoch 41: loss did not improve from 0.00245\n",
      "94/94 [==============================] - 24s 251ms/step - loss: 0.0027 - mean_absolute_error: 0.0134 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0137\n",
      "Epoch 42: loss did not improve from 0.00245\n",
      "94/94 [==============================] - 24s 251ms/step - loss: 0.0027 - mean_absolute_error: 0.0137 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0131\n",
      "Epoch 43: loss improved from 0.00245 to 0.00232, saving model to pesos.h5\n",
      "94/94 [==============================] - 25s 267ms/step - loss: 0.0023 - mean_absolute_error: 0.0131 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0124\n",
      "Epoch 44: loss did not improve from 0.00232\n",
      "94/94 [==============================] - 24s 261ms/step - loss: 0.0024 - mean_absolute_error: 0.0124 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0127\n",
      "Epoch 45: loss did not improve from 0.00232\n",
      "94/94 [==============================] - 23s 243ms/step - loss: 0.0023 - mean_absolute_error: 0.0127 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0129\n",
      "Epoch 46: loss improved from 0.00232 to 0.00229, saving model to pesos.h5\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0023 - mean_absolute_error: 0.0129 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0129\n",
      "Epoch 47: loss did not improve from 0.00229\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0024 - mean_absolute_error: 0.0129 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0119\n",
      "Epoch 48: loss improved from 0.00229 to 0.00205, saving model to pesos.h5\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0021 - mean_absolute_error: 0.0119 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0131\n",
      "Epoch 49: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0027 - mean_absolute_error: 0.0131 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0118\n",
      "Epoch 50: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 24s 261ms/step - loss: 0.0021 - mean_absolute_error: 0.0118 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0121\n",
      "Epoch 51: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 23s 247ms/step - loss: 0.0022 - mean_absolute_error: 0.0121 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0120\n",
      "Epoch 52: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 25s 263ms/step - loss: 0.0022 - mean_absolute_error: 0.0120 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0124\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 25s 263ms/step - loss: 0.0025 - mean_absolute_error: 0.0124 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0126\n",
      "Epoch 54: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 24s 260ms/step - loss: 0.0025 - mean_absolute_error: 0.0126 - lr: 8.0000e-06\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0128\n",
      "Epoch 55: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0026 - mean_absolute_error: 0.0128 - lr: 8.0000e-06\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0121\n",
      "Epoch 56: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0023 - mean_absolute_error: 0.0121 - lr: 8.0000e-06\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0120\n",
      "Epoch 57: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 25s 262ms/step - loss: 0.0022 - mean_absolute_error: 0.0120 - lr: 8.0000e-06\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0122\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00205\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0023 - mean_absolute_error: 0.0122 - lr: 8.0000e-06\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65498"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Server::ConsolidateModels----------------Server::FeedBackConsolidatedModel--------------Client::RefreshModel\n",
    "'''\n",
    "\n",
    "#numClients = 3; #Can be gotten from user\n",
    "\n",
    "#lstClients = [];\n",
    "\n",
    "objServe = Server_FederatedAMA()\n",
    "\n",
    "#for i in range (numClients):\n",
    "  #objClient = Client(objServe,i)\n",
    "  #lstClients.append(objClient)\n",
    "\n",
    "#for x in lstClients:\n",
    "  #print(\"Cliente \", x.id, \"Criado com Sucesso\");\n",
    "\n",
    "\n",
    "#for x in lstClients:\n",
    " #objServe.RegisterClient(x)\n",
    "\n",
    "#objServe.PrintRegistredClients()\n",
    "\n",
    "'''\n",
    "for i in range (0,10):\n",
    "  print(\"==================Rodada \",i\" ========================\")\n",
    "  for x in lstClients:\n",
    "    x.TreinarModelo\n",
    "  for x in lstClients:\n",
    "    x.SendModelToServer\n",
    "  objServe.ConsolidateModels\n",
    "  objServe.FeedBackConsolidatedModel()\n",
    "  for x in lstClients:\n",
    "    x.AtualizarModelo();\n",
    "'''\n",
    "\n",
    "objClient1 = Client(0,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client01_Fri Feb 24 10_09_37.csv',\n",
    "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
    "\n",
    "#objClient1.LoadTainingDataSet()\n",
    "\n",
    "\n",
    "objClient1.RefreshModel(parInitial=True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "objClient2 = Client(1,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client02_Fri Feb 24 10_09_37.csv',\n",
    "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
    "\n",
    "#objClient2.LoadTainingDataSet()\n",
    "\n",
    "objClient2.RefreshModel(parInitial=True)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "objClient3 = Client(2,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client03_10_1_2_2to10_35_0_2_trainingFri Feb 24 10_09_37.csv',\n",
    "                               '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
    "\n",
    "#objClient3.LoadTainingDataSet()\n",
    "objClient3.RefreshModel(parInitial=True)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ynh0ZgIyKk4t",
    "outputId": "d7f79934-910a-4cb3-a6ee-83772ae0b186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 2s 61ms/step\n",
      "[[ 0  4  5]\n",
      " [52 75  0]\n",
      " [64  0  0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 2s 66ms/step\n",
      "[[  0   0   9]\n",
      " [  0   0 127]\n",
      " [  0   0  64]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 3s 81ms/step\n",
      "[[  0   0   9]\n",
      " [  0   0 127]\n",
      " [  0   0  64]]\n",
      "Amostra Peso Clientes:\n",
      "============================\n",
      "[ 0.00236063  0.01440284  0.05232135 -0.09341507]\n",
      "============================\n",
      "[-0.02274335  0.02013068 -0.01957721  0.03507286]\n",
      "============================\n",
      "[ 0.02095836 -0.05965294 -0.0283191   0.08724292]\n",
      "Amostra Peso Consolidado: \n",
      "[ 0.00019188 -0.00837314  0.00147501  0.00963357]\n",
      "Cliente  0  Recebido Modelo do Servidor\n",
      "Cliente  1  Recebido Modelo do Servidor\n",
      "Cliente  2  Recebido Modelo do Servidor\n",
      "Feedbacks Enviados\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 2s 63ms/step\n",
      "Modelo do Servidor avaliado\n",
      "Pesos atualizados de acordo com o modelo do servidor\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 2s 64ms/step\n",
      "Modelo do Servidor avaliado\n",
      "Pesos atualizados de acordo com o modelo do servidor\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 3s 60ms/step\n",
      "Modelo do Servidor avaliado\n",
      "Pesos atualizados de acordo com o modelo do servidor\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 2s 63ms/step\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 3s 64ms/step\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n",
      "#############len(base_teste):  200\n",
      "7/7 [==============================] - 3s 64ms/step\n",
      "[[  0   9   0]\n",
      " [  0 127   0]\n",
      " [  0  64   0]]\n"
     ]
    }
   ],
   "source": [
    "###################Testando#################################\n",
    "\n",
    "#objClient1.LoadTestData()\n",
    "objClient1.GetPrevision()\n",
    "print (objClient1.currentConfusionMatriz)\n",
    "\n",
    "#objClient2.LoadTestData()\n",
    "objClient2.GetPrevision()\n",
    "print (objClient2.currentConfusionMatriz)\n",
    "\n",
    "\n",
    "#objClient3.LoadTestData()\n",
    "objClient3.GetPrevision()\n",
    "print (objClient3.currentConfusionMatriz)\n",
    "\n",
    "#########################Registrando no Servidor Central#######################################\n",
    "\n",
    "objServe.RegisterClient(objClient1)\n",
    "objServe.RegisterClient(objClient2)\n",
    "objServe.RegisterClient(objClient3)\n",
    "\n",
    "#########################Consolidando os modelos#######################################\n",
    "\n",
    "objServe.ConsolidateModels()\n",
    "objServe.FeedBackConsolidatedModel()\n",
    "\n",
    "#########################Testando o novo modelo#######################################\n",
    "#########################Atualizando, conforme o caso#######################################\n",
    "\n",
    "objClient1.RefreshModel()\n",
    "print (objClient1.currentConfusionMatriz)\n",
    "objClient2.RefreshModel()\n",
    "print (objClient2.currentConfusionMatriz)\n",
    "objClient3.RefreshModel()\n",
    "print (objClient2.currentConfusionMatriz)\n",
    "\n",
    "#########################Novas matrizes, após atualização ou não dos modelos#######################################\n",
    "\n",
    "objClient1.GetPrevision()\n",
    "print (objClient1.currentConfusionMatriz)\n",
    "objClient2.GetPrevision()\n",
    "print (objClient2.currentConfusionMatriz)\n",
    "objClient3.GetPrevision()\n",
    "print (objClient3.currentConfusionMatriz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKDnx_BcTkT-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrgtR0tPduXFKes7eE9KEl",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
