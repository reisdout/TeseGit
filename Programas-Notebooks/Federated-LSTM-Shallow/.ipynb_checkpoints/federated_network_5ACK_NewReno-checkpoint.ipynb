{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d2199c",
   "metadata": {},
   "source": [
    "# NewReno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd206ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import ion\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import RegressorMixin\n",
    "from tensorflow.python import training\n",
    "#%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import os \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eed0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  \n",
    "class Server_FederatedOMS:\n",
    "  \n",
    "  In the central server, we decide to use only the highest\n",
    "  accuracy holder model as the central server updated model, send it to the local\n",
    "  clients after the computation.\n",
    "\n",
    "\n",
    "\n",
    "  def ReceiveModelsFromClients(self, parIdCliente):\n",
    "    print(\"Recebido Modelo do Cliente 1\")\n",
    "  def Consolidar(self):\n",
    "    print(\"Consolidado todos os modelos\")\n",
    "  def FeedBackConsolidatedModel(self):\n",
    "    print (\"Modelos enviados\")\n",
    "\n",
    "  clients = ['Cliente1', 'Cliente2']\n",
    "\n",
    "\n",
    "class Server_FederatedBMA():\n",
    "\n",
    "owever, in the BMA technique, the central server receives\n",
    "four models with model accuracy performances from the local servers or clients.\n",
    "In the central server, we sort the model using their performances. Then we\n",
    "decide to use the two best models or half of the models based on performances.\n",
    "Then BMA technique loops through each model’s hidden layers and neurons to do\n",
    "the sum of the weights and average them accordingly.\n",
    "\n",
    "  def ReceiveModelsFromClients(self)\n",
    "  def Consolidar(self)\n",
    "  def FeedBackConsolidatedModel(self)\n",
    "\n",
    "    clients[] = ['Cliente1', 'Cliente2']\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, parCentralServer, parId):\n",
    "      self.id=parId\n",
    "      self.centralServer = parCentralServer\n",
    "      #self.centralServer.RegisterClient(self,self)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class LoggingCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Callback that logs message at end of epoch.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, parExpDir):\n",
    "       \n",
    "        self.exp_dir = parExpDir\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        \n",
    "        file_path = self.exp_dir+\"/readme.txt\"\n",
    "\n",
    "        f = open(file_path, \"a\")\n",
    "        msg = \"{Epoch: %i} %s\" % (epoch, \", \".join(\"%s: %f\" % (k, v) for k, v in logs.items()))\n",
    "        f.write(msg+\"\\n\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "\n",
    "class Client():\n",
    "\n",
    "\n",
    "\n",
    "    #resultadoTreinamento = np.eye(10)\n",
    "\n",
    "    def __init__(self,\n",
    "                 parId,\n",
    "                 parTraininPath, \n",
    "                 parTestPath, \n",
    "                 parEpoch,\n",
    "                 parUnits, \n",
    "                 parBatchSize, \n",
    "                 parPrevisionWindow, \n",
    "                 parStepsOut,\n",
    "                 parCongestionProtocol,\n",
    "                 parNumWebNodes, \n",
    "                 parRTTToRouter,\n",
    "                 parExpTime,\n",
    "                 parExpDir,\n",
    "                 par_exp_dir_out_from_fit,\n",
    "                 par_exp_dir_out_from_file):\n",
    " \n",
    "      self.id = parId\n",
    "      self.id_in_server=-1 #-1 indica que não foi cadastrado no servidor\n",
    "      self.trainingPath=parTraininPath\n",
    "      self.testPath = parTestPath\n",
    "      self.T = parPrevisionWindow\n",
    "      #centralServer = Server_FederatedAMA()\n",
    "      #confusionMatrizModelClient = np.full((2,2), 1)\n",
    "      #confusionMatrizModelServer = np.full((2,2), 2)\n",
    "      self.currentConfusionMatriz =np.full((2,2), 0) # Apesar de ser obtidas a partir de listas, a matriz de comfusão é numpy\n",
    "      self.weightsClientModel = []\n",
    "      self.weightsServerModel = []\n",
    "      #self.total_ConsolidateModels=0;\n",
    "      #self.base = pd.DataFrame()\n",
    "      #self.base_treinamento =  np.array([])\n",
    "      self.real_congestion_test = np.array([])\n",
    "      self.latest_prevision = np.array([])\n",
    "      #self.test_vectors = []\n",
    "      #self.previsores = []\n",
    "      #self.real_congestion = []\n",
    "      #self.regressor = Sequential()\n",
    "      self.input_shape =0;\n",
    "      self.base_teste=[]\n",
    "      self.len_base_teste = 0;\n",
    "      self.n_steps_out = parStepsOut\n",
    "      self.congestion_protocol = parCongestionProtocol\n",
    "      self.mean_real_congestion = 0;\n",
    "      self.mean_predicted_congestion=0;\n",
    "      #self.windowMemory = parWindowMemory #substituido pela unit\n",
    "      self.exp_units=parUnits\n",
    "      self.exp_batch_size=parBatchSize\n",
    "      self.exp_num_web_nodes=parNumWebNodes;\n",
    "      self.exp_RTT_to_router=parRTTToRouter;\n",
    "      self.exp_epoch=parEpoch\n",
    "      self.exp_time=parExpTime\n",
    "      self.exp_dir = parExpDir\n",
    "      self.num_plot = 0;\n",
    "      self.last_server_type_sender = \"AMA\" #AMA, INTERCHANGE\n",
    "      self.total_model_received_form_server=0\n",
    "      self.model_saves = 0\n",
    "      self.exp_dir_out_from_fit = par_exp_dir_out_from_fit\n",
    "      self.exp_dir_out_from_file =par_exp_dir_out_from_file\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "      #self.centralServer.RegisterClient(self,self)\n",
    "\n",
    "    def NormalizeFeatures(self, data):\n",
    "\n",
    "       data['ack_ewma(ms)'] = data['ack_ewma(ms)'].div(data['ack_ewma(ms)'].max())\n",
    "       data['send_ewma(ms)'] = data['send_ewma(ms)'].div(data['send_ewma(ms)'].max())\n",
    "       data['rtt_ratio'] = data['rtt_ratio'].div(data['rtt_ratio'].max())\n",
    "       data['cwnd (Bytes)'] = data['cwnd (Bytes)'].div(data['cwnd (Bytes)'].max())\n",
    "       return data\n",
    "\n",
    "    def SplitBase(self, base):\n",
    "      training_base = base.iloc[0:base.shape[0]-200,:]\n",
    "      teste = base.iloc[base.shape[0]-200:base.shape[0],:]\n",
    "      return training_base, teste\n",
    "\n",
    "\n",
    "    \n",
    "    def RefreshFromServerModel(self):\n",
    "      if(self.ServerModelIsBetter()):\n",
    "          print(\"Pesos atualizados de acordo com o modelo do servidor\")\n",
    "          return True\n",
    "      else:\n",
    "          print(\"Pesos Mantidos de acordo com o modelo do cliente\")\n",
    "          return False\n",
    "\n",
    "    def LoadTrainingDataSet(self):\n",
    "      base = pd.read_csv(self.trainingPath)\n",
    "      base = base.dropna()\n",
    "      base = self.NormalizeFeatures(base)\n",
    "      base_treinamento, self.base_teste = self.SplitBase(base)\n",
    "      base_treinamento = base.iloc[:, [1,2,3,4,5]].values\n",
    "      #base_treinamento = base.iloc[:, [1,2,3,5]].values\n",
    "      #print(\"Veja a base de treinamento normalizada\")\n",
    "      #print(base_treinamento)\n",
    "      #input();\n",
    "      #normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "      #base_treinamento = normalizador.fit_transform(base_treinamento)\n",
    "      #base_treinamento = base.iloc[:, [2,4,6]].values\n",
    "      previsores=[]\n",
    "      real_congestion = []\n",
    "\n",
    "      #real_congestion_ahead = []\n",
    "\n",
    "      #base_treinamento.shape[0] número de linhas dos dados de treinamento\n",
    "      #\"-self.n_steps_out\", pois, se não estoura, não dá para fazer 5 a frente a partir do último                                                                   \n",
    "      for i in range(self.T, base_treinamento.shape[0]):\n",
    "        end_ix = i+self.n_steps_out\n",
    "        if end_ix > base_treinamento.shape[0]:\n",
    "          break;\n",
    "        #previsores.append(base_treinamento[i-self.T:i, 0:4])#o que é considerado é o limite superior do rante -1\n",
    "        previsores.append(base_treinamento[i-self.T:i, 0:4])#o que é considerado é o limite superior do rante -1 e sem a informação do percentual de ocupação do buffer\n",
    "        real_congestion.append(base_treinamento[(i-1)+self.n_steps_out,4])#\n",
    "    \n",
    "        '''\n",
    "        #Se quiser repetir os últimos valores\n",
    "        real_congestion_ahead.clear();\n",
    "        \n",
    "        for k in range (self.n_steps_out):\n",
    "          if i+k < base_treinamento.shape[0]:\n",
    "            #print(i+k,\"---> \", base_treinamento[i+k, 3])\n",
    "            real_congestion_ahead.append(base_treinamento[i+k, 4])#O resultado é do último cara\n",
    "          else:\n",
    "            real_congestion_ahead.append(base_treinamento[base_treinamento.shape[0]-1, 4])#O resultado é do último cara\n",
    "        real_congestion.append(real_congestion_ahead.copy())\n",
    "        '''\n",
    "        #print(real_congestion)\n",
    "        #input(\"real_congestion ++\")\n",
    "      '''\n",
    "      *********************************SOBRE O RESHAPE**************************************\n",
    "      Veja que nesse caso não é necessário fazer o reshape, uma vez que o array previsores , já sai\n",
    "      no formato [samples, timesteps, features]\n",
    "      *sample: Ajanela deslizante em T vai gerar um número de inserções em previsores, correspondente ao número de samples\n",
    "      *timesteps:inserções de exatamente T arrays, que nesse caso é equivalente ao timestamps, ou seja, quantas leituras no tempo estamos \n",
    "      considerando para prever. \n",
    "      *features: T arrays de n features\n",
    "\n",
    "      no nosso caso:\n",
    "\n",
    "      seja\n",
    "\n",
    "      base_treinamento = np.array([\n",
    "                          [0.0618679825944638,1.48529333300134E-05,0.849658635009267,\t1,\t0.8],\n",
    "                          [0.0618642722717276,1.29963255564132E-05,0.856697088426436,0.960369635326222,0.8],\n",
    "                          [0.061861180336114,\t1.13717804155358E-05,0.863735541843606,0.915095509799057,\t0.78],\n",
    "                          [0.0618582945295414,9.95030786359384E-06,0.870773995260775,0.892458447035475,\t0.76],\n",
    "                          [0.0620104177617272,8.70651048799314E-06,0.877953217746287,0.869821384271893,\t0.74],\n",
    "                          [0.06214357712215,  7.6182100159712E-06, 0.8851324402318,0.860208385016125,\t0.72],\n",
    "                          [0.0622600400302597\t,6.66593154081194E-06\t,0.892311662717312,0.847184321508311,\t0.7],\n",
    "                          [0.0623620739055063\t,5.83269009821044E-06\t,0.899490885202825,\t0.847184321508311,\t0.68],\n",
    "                          [0.0624511216511761\t,5.1035993896084E-06,0.906670107688337,0.847184321508311,\t0.69],\n",
    "                          [0.062529244557678\t,4.46565835855882E-06\t,0.91384933017385\t,0.847184321508311,\t0.78],\n",
    "                          [0.0625974732702166,3.9074488405761E-06\t,0.921028552659362\t,0.847184321508311,\t0.58],\n",
    "                          [0.0626572506920783\t,3.41901106601549E-06\t,0.928207775144875,0.847184321508311,\t0.48],\n",
    "                          [0.0627096074684674\t,2.99163023643782E-06\t,0.935386997630387,0.847184321508311,\t0.38],\n",
    "                          [0.0627553681155477\t,2.61767645688309E-06\t,0.9425662201159,0.0226370627635822,\t0.18],\n",
    "                          [0.0627953571494827\t,2.29048023874991E-06\t,0.949745442601412,0.0226370627635822,\t0.28],\n",
    "\n",
    "\n",
    "      ])\n",
    "\n",
    "\n",
    "      ou seja 15 samples, 4 features e uma a ser prevista. Vamos considerar T=3 e n_steps_out=4(n_steps_out=0 já é um a frente, ou seja tem que bater em T)  \n",
    "      Daí só vai sobrar 15-(T+n_steps_out-1= 3+4-1) = 9 samples\n",
    "      a saída será\n",
    "\n",
    "      previsores\n",
    "             1               2              3             4\n",
    "    1  [[6.18679826e-02 1.48529333e-05 8.49658635e-01 1.00000000e+00]\n",
    "      T [6.18642723e-02 1.29963256e-05 8.56697088e-01 9.60369635e-01]\n",
    "        [6.18611803e-02 1.13717804e-05 8.63735542e-01 9.15095510e-01]] 0.7\n",
    "    2  [[6.18642723e-02 1.29963256e-05 8.56697088e-01 9.60369635e-01]\n",
    "      T [6.18611803e-02 1.13717804e-05 8.63735542e-01 9.15095510e-01]\n",
    "        [6.18582945e-02 9.95030786e-06 8.70773995e-01 8.92458447e-01]] 0.68\n",
    "    3[  [6.18611803e-02 1.13717804e-05 8.63735542e-01 9.15095510e-01]\n",
    "      T [6.18582945e-02 9.95030786e-06 8.70773995e-01 8.92458447e-01]\n",
    "        [6.20104178e-02 8.70651049e-06 8.77953218e-01 8.69821384e-01]] 0.69\n",
    "    4[  [6.18582945e-02 9.95030786e-06 8.70773995e-01 8.92458447e-01]\n",
    "      T [6.20104178e-02 8.70651049e-06 8.77953218e-01 8.69821384e-01]\n",
    "        [6.21435771e-02 7.61821002e-06 8.85132440e-01 8.60208385e-01]] 0.78\n",
    "    5[  [6.20104178e-02 8.70651049e-06 8.77953218e-01 8.69821384e-01]\n",
    "      T [6.21435771e-02 7.61821002e-06 8.85132440e-01 8.60208385e-01]\n",
    "        [6.22600400e-02 6.66593154e-06 8.92311663e-01 8.47184322e-01]] 0.58\n",
    "    6[  [6.21435771e-02 7.61821002e-06 8.85132440e-01 8.60208385e-01]\n",
    "      T [6.22600400e-02 6.66593154e-06 8.92311663e-01 8.47184322e-01]\n",
    "        [6.23620739e-02 5.83269010e-06 8.99490885e-01 8.47184322e-01]] 0.48\n",
    "    7[  [6.22600400e-02 6.66593154e-06 8.92311663e-01 8.47184322e-01]\n",
    "      T [6.23620739e-02 5.83269010e-06 8.99490885e-01 8.47184322e-01]\n",
    "        [6.24511217e-02 5.10359939e-06 9.06670108e-01 8.47184322e-01]] 0.38\n",
    "    8[  [6.23620739e-02 5.83269010e-06 8.99490885e-01 8.47184322e-01]\n",
    "      T [6.24511217e-02 5.10359939e-06 9.06670108e-01 8.47184322e-01]\n",
    "        [6.25292446e-02 4.46565836e-06 9.13849330e-01 8.47184322e-01]] 0.18\n",
    "    9[  [6.24511217e-02 5.10359939e-06 9.06670108e-01 8.47184322e-01]\n",
    "      T [6.25292446e-02 4.46565836e-06 9.13849330e-01 8.47184322e-01]\n",
    "        [6.25974733e-02 3.90744884e-06 9.21028553e-01 8.47184322e-01]] 0.28\n",
    "\n",
    "          ou seja\n",
    "          [samples,timestepes,features]\n",
    "\n",
    "      '''\n",
    "      previsores, real_congestion = np.array(previsores), np.array(real_congestion)\n",
    "      '''\n",
    "      print(\"shape previsores: \")\n",
    "      print(previsores.shape)\n",
    "      #input(\"shape dos previsores\")\n",
    "      print(\"Amostra Previsores\")      \n",
    "      print(previsores[0])\n",
    "      print(previsores[1])\n",
    "      print(previsores[2])\n",
    "      #input(\"Amostra Previsores Exibidos acima\")\n",
    "      print(\"Real Congestion: \")\n",
    "      print(real_congestion)\n",
    "      #input(\"exibidos os Congestionamentos Reais\")\n",
    "      '''\n",
    "      self.input_shape = previsores.shape[1]\n",
    "      return previsores, real_congestion\n",
    "      \n",
    "    def GetModel(self):\n",
    "      regressor = Sequential()\n",
    "      #regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 4, pois são 4 previsores\n",
    "      #regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))# 3, retirando o valor do preenchimento do buffer.\n",
    "      #regressor.add(Bidirectional(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4))))\n",
    "      #regressor.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
    "\n",
    "      #regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (self.input_shape, 4)))\n",
    "      #regressor.add(LSTM(units = 20, return_sequences = True, input_shape = (self.input_shape, 4)))\n",
    "      #regressor.add(LSTM(units = 10, return_sequences = True, input_shape = (self.input_shape, 4)))\n",
    "      #regressor.add(LSTM(units = 6, return_sequences = True, input_shape = (self.input_shape, 4)))\n",
    "      regressor.add(LSTM(units = 2*self.exp_units, return_sequences = True, input_shape = (self.input_shape, 4)))\n",
    "      regressor.add(Dropout(0.3)) #zerar 30% das entradas para evitar o overfiting\n",
    "      \n",
    "      \n",
    "      #regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "      #regressor.add(LSTM(units = 10, return_sequences = True))\n",
    "      #regressor.add(LSTM(units = 6, return_sequences = True))\n",
    "      regressor.add(LSTM(units = self.exp_units, return_sequences = True))\n",
    "      regressor.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "      #regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "      #regressor.add(LSTM(units = 10, return_sequences = True))\n",
    "      #regressor.add(LSTM(units = 6, return_sequences = True))\n",
    "      regressor.add(LSTM(units = self.exp_units, return_sequences = True))\n",
    "      regressor.add(Dropout(0.3))\n",
    "\n",
    "      #regressor.add(LSTM(units = 50))\n",
    "      #regressor.add(LSTM(units = 10))\n",
    "      #regressor.add(LSTM(units = 6))\n",
    "      regressor.add(LSTM(units = self.exp_units))\n",
    "      regressor.add(Dropout(0.3))\n",
    "\n",
    "      '''\n",
    "      Segundo https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "      as saídas de cada unidade da LSTM e, portanto, a saída global é a dimenção do número de previsores, que, no nosso\n",
    "      caso, é 4. Daí esses 4 estão sendo levados em um softmax de tres neurônios, pois há tres categorias no final\"\n",
    "      ''' \n",
    "      #regressor.add(Dense(units = 1, activation = 'sigmoid', name=\"client_\"+str(self.id))) #para uma previsão\n",
    "      regressor.add(Dense(units = self.n_steps_out, activation = 'sigmoid', name=\"client_\"+str(self.id)))\n",
    "      \n",
    "      #regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
    "\n",
    "      return regressor\n",
    "\n",
    "    def GetModelFromFile(self, parSave):\n",
    "\n",
    "      arquivo = open(self.exp_dir+\"/model_\"+str(parSave)+\".json\",'r')\n",
    "      estrutura_regressor = arquivo.read()\n",
    "      arquivo.close()\n",
    "      regressor = model_from_json(estrutura_regressor)\n",
    "      regressor.load_weights(self.exp_dir+\"/model_weights_\"+str(parSave)+\".h5\")\n",
    "      #Atualiza a lista de pesos, só para manter a coerencia, pois os pesos já estão no regressor\n",
    "      #mas devem também ser os pesos atuais do cliente, pelo qual está pervendo\n",
    "      self.weightsClientModel.clear()\n",
    "      for e in regressor.get_weights():\n",
    "        self.weightsClientModel.append(e)\n",
    "      return regressor\n",
    "\n",
    "\n",
    "    def RefreshModel(self, parInitial=False): #Constroi na primeira vez e atualiza, a partir da avaliação do servidor cetral\n",
    "      #pensar melhor no critério\n",
    "      previsores,real_congestion = self.LoadTrainingDataSet()\n",
    "\n",
    "      #regressor = Sequential()\n",
    "      regressor = self.GetModel();\n",
    "      #indica que já foi feito um treinamento ou consolidação de modelos prévia\n",
    "      if(len (self.weightsClientModel)):\n",
    "        regressor.set_weights(self.weightsClientModel)      \n",
    "\n",
    "      opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "      regressor.compile(optimizer = opt, loss = 'mean_squared_error',metrics = ['mean_absolute_error'])\n",
    "      #es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
    "      #rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
    "      #mcp = ModelCheckpoint(filepath = self.exp_dir+\"/pesos.h5\", monitor = 'loss',  save_weights_only = True, save_freq='epoch',verbose = 1)\n",
    "      #regressor.fit(previsores, real_congestion, epochs = 50, batch_size = 32, callbacks = [es, rlr, mcp])\n",
    "      regressor.fit(previsores, real_congestion, epochs = self.exp_epoch, batch_size = self.exp_batch_size,verbose=0,\n",
    "                callbacks=[LoggingCallback(parExpDir=self.exp_dir)])\n",
    "      #self.weightsClientModel = regressor.get_weights().copy()\n",
    "      regressor_json = regressor.to_json()\n",
    "      with open(self.exp_dir+\"/model_\"+str(self.model_saves)+\".json\",'w') as json_file:\n",
    "        json_file.write(regressor_json)\n",
    "      regressor.save_weights(self.exp_dir+\"/model_weights_\"+str(self.model_saves)+\".h5\")\n",
    "      self.model_saves=self.model_saves+1\n",
    "      self.weightsClientModel.clear()\n",
    "      for e in regressor.get_weights():\n",
    "        self.weightsClientModel.append(e)\n",
    "\n",
    "\n",
    "    #Apenas abre o arquivo e carrega os pesos. Falta Completar, pois os certo é continuar um treinamento a partir do modeo carregado \n",
    "    def RefreshModelFromFile(self, parSave): #Constroi na primeira vez e atualiza, a partir da avaliação do servidor cetral\n",
    "      \n",
    "      #regressor = self.GetModelFromFile(parSave);\n",
    "      #regressor.load_weights(exp_dir+\"/model_weights_\"+str(parSave)+\".h5\")\n",
    "      regressor=self.GetModelFromFile(parSave)\n",
    "\n",
    "      #Implementar o treinamento falta completar\n",
    "      #no final atualiza so pesos\n",
    "      self.weightsClientModel.clear()\n",
    "      for e in regressor.get_weights():\n",
    "        self.weightsClientModel.append(e)\n",
    "\n",
    " \n",
    "    def GetMapedMatrix(self,parPrevisoes):\n",
    "      classe_teste2 = []\n",
    "      previsoes2 =  []\n",
    "\n",
    "      for i in range(0, self.len_base_teste):\n",
    "        if(self.real_congestion_test[i,0] < 0.3):\n",
    "          classe_teste2.append(0)\n",
    "        elif (self.real_congestion_test[i,0] >= 0.3 and self.real_congestion_test[i,0] < 0.75):\n",
    "          classe_teste2.append(1)\n",
    "        else:\n",
    "          classe_teste2.append(2)\n",
    "\n",
    "      for i in range(0, parPrevisoes.shape[0]):\n",
    "        if(parPrevisoes[i,0] < 0.3):\n",
    "          previsoes2.append(0)\n",
    "        elif (parPrevisoes[i,0] >= 0.3 and parPrevisoes[i,0] < 0.75):\n",
    "          previsoes2.append(1)\n",
    "        else:\n",
    "          previsoes2.append(2)\n",
    "\n",
    "      return classe_teste2, previsoes2\n",
    "\n",
    "\n",
    "    def EvalueteServerModel(self, parServerModel):\n",
    "\n",
    "      test_vectors = self.LoadTestData()\n",
    "      updated = False\n",
    "      for i in range(0,self.total_model_received_form_server):\n",
    "        print(f\"====== Cliente: {self.id} analisando modelo {i} do servidor:\")\n",
    "        #É importante lembrar que o GetPrevision faz a previsão com os pesos que lá estiverem! \n",
    "        previsoesCliente = self.GetPrevision()\n",
    "        if(self.last_server_type_sender == \"AMA\"):#uma unica lista\n",
    "          parServerModel.set_weights(self.weightsServerModel)\n",
    "        elif (self.last_server_type_sender == \"INTERCHANGE\"):#várias listas\n",
    "          parServerModel.set_weights(self.weightsServerModel[i])\n",
    "        else:\n",
    "          print(\"Tipo de Servidor Incompatível\")\n",
    "          quit();\n",
    "        previsoesServidor = parServerModel.predict(test_vectors)\n",
    "        \n",
    "        '''\n",
    "        Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
    "        do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
    "        '''\n",
    "        '''\n",
    "        Abordagem baseada na matriz de confusão, abandonada por se entender que o melhor é verificar a tendência.\n",
    "        classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes)\n",
    "        matriz = confusion_matrix(classe_teste2,previsoes2)\n",
    "        currentSum = 0\n",
    "        newSum = 0\n",
    "        if(self.currentConfusionMatriz.ndim > 1): # as vezes a rede pode errar ao ponto de dar só uma categoria, daí cai no else...\n",
    "          for i in range (0, len(self.currentConfusionMatriz)):\n",
    "            currentSum = currentSum + self.currentConfusionMatriz[i][i]\n",
    "        else:\n",
    "          currentSum = self.currentConfusionMatriz[i]\n",
    "        if(matriz.ndim > 1):\n",
    "          for i in range (0, len(matriz)):\n",
    "            newSum = newSum + matriz[i][i]\n",
    "       else:\n",
    "          newSum = matriz[i]\n",
    "        if(newSum > currentSum):\n",
    "          self.currentConfusionMatriz = np.array(matriz)\n",
    "          #self.regressor.set_weights(self.weightsServerModel)\n",
    "          self.weightsClientModel.clear()\n",
    "          for e in self.weightsServerModel:\n",
    "            self.weightsClientModel.append(e)\n",
    "          updated = True\n",
    "      '''\n",
    "        #print(\"====== Média dos Congestionamentos Previstos com modelo central: \",previsoes.mean())\n",
    "        \n",
    "        print(\"====== Erro médio com modelo servidor: \",np.mean(abs(previsoesServidor[:,self.n_steps_out-1]-self.real_congestion_test)))\n",
    "        print(\"====== Erro médio com modelo cliente: \",np.mean(abs(previsoesCliente[:,self.n_steps_out-1]-self.real_congestion_test)))\n",
    "        #if abs(previsoes.mean()-self.mean_real_congestion) < abs(self.mean_predicted_congestion-self.mean_real_congestion):\n",
    "        #Observe que se houver mais de um modelo consolidad, o melhor prevalece, pois a próxima previsão\n",
    "        #é comparada com a do melhor medolo, pois o modelo vigente sempre é substituído caso o do servidor central \n",
    "        #seja melhor\n",
    "        if np.mean(abs(previsoesServidor[:,self.n_steps_out-1]-self.real_congestion_test)) < np.mean(abs(previsoesCliente[:,self.n_steps_out-1]-self.real_congestion_test)):\n",
    "          self.weightsClientModel.clear()\n",
    "          if(self.last_server_type_sender == \"AMA\"):\n",
    "            for e in self.weightsServerModel:\n",
    "              self.weightsClientModel.append(e)\n",
    "          elif (self.last_server_type_sender == \"INTERCHANGE\"):\n",
    "            for e in self.weightsServerModel[i]:\n",
    "              self.weightsClientModel.append(e)\n",
    "\n",
    "          self.mean_predicted_congestion = previsoesServidor.mean();\n",
    "          updated = True        \n",
    "\n",
    "      print (f\"Modelo do Servidor avaliado pelo cliente {self.id}\")\n",
    "      return updated \n",
    "\n",
    "    def LoadTestData(self, parLoadTestFromFile=False):\n",
    "      #Esse if é pensado na hora de testar o modelo com dados de outros experimentos, completamente\n",
    "      #alheisos com os que foram treinados \n",
    "      if(parLoadTestFromFile): #Daí pega o testPath, que, a princípio, é um experimento diferente daquele para no qual os\n",
    "                               #pesos salvos foram treinados\n",
    "        print(\"From File\")\n",
    "        base = pd.read_csv(self.testPath)\n",
    "        base = base.dropna()\n",
    "        base = self.NormalizeFeatures(base)\n",
    "        base_treinamento, external_base_teste = self.SplitBase(base)\n",
    "        self.real_congestion_test = external_base_teste.iloc[:, 5:6].values\n",
    "        frames = [base_treinamento, external_base_teste]\n",
    "        base_completa = pd.concat(frames)\n",
    "        self.len_base_teste = len(external_base_teste)\n",
    "      else: #caminho normal, durante o treinamento\n",
    "        base = pd.read_csv(self.trainingPath)\n",
    "        base = base.dropna()\n",
    "        base = self.NormalizeFeatures(base)\n",
    "        base_treinamento, external_base_teste = self.SplitBase(base)\n",
    "        #A base teste está sendo preparada no SplitBase\n",
    "        #base_teste = pd.read_csv(self.testPath)\n",
    "        #base_teste = base_teste.dropna()\n",
    "        #base_teste = self.NormalizeFeatures(base_teste)\n",
    "        self.real_congestion_test = self.base_teste.iloc[:, 5:6].values #Observe que aqui não há drop, por isso é 5:6, de Ack a Last Router Ocupation Ack Arriaval(Packets)\n",
    "        #self.real_congestion_test = base_teste.iloc[:, 9:10].values      \n",
    "        #print(\"antes de deslocar\")\n",
    "        #print(self.real_congestion_test)\n",
    "        frames = [base_treinamento, self.base_teste]\n",
    "        base_completa = pd.concat(frames)\n",
    "        self.len_base_teste = len(self.base_teste)\n",
    "      '''\n",
    "        A ideia do laço a seguir é 'shiftar' o congestionamento real de n_steps_out, a fim de se fazer a comparação\n",
    "        com o última posição dos vetores previstos pela rede neural.\n",
    "      \n",
    "        for k in range (base_teste.shape[0]):\n",
    "              if(k+self.n_steps_out < base_teste.shape[0]):\n",
    "              self.real_congestion_test[k][0] = self.real_congestion_test[k+self.n_steps_out-1][0]\n",
    "          else:\n",
    "            self.real_congestion_test[k][0] = self.real_congestion_test[base_teste.shape[0]-1][0]\n",
    "      '''\n",
    "      self.mean_real_congestion = self.real_congestion_test.mean()\n",
    "      #print(\"====== Média dos Congestionamentos: \",self.mean_real_congestion)\n",
    "      #print(\"observe os valores de teste deslocados\")\n",
    "      #print(self.real_congestion_test.shape)\n",
    "      #print(self.real_congestion_test)\n",
    "      #input(\"Veja se foi feito o deslocamento corretamente\")\n",
    "\n",
    "\n",
    "      base_completa = base_completa.drop('#Ack', axis =1) #\n",
    "      #base_completa = base_completa.drop('ack_ewma(ms)', axis =1)\n",
    "      #base_completa = base_completa.drop('send_ewma(ms)', axis =1)\n",
    "      #base_completa = base_completa.drop('rtt_ratio', axis =1)\n",
    "      #base_completa = base_completa.drop('cwnd (Bytes)', axis =1)\n",
    "      base_completa = base_completa.drop('Last Router Ocupation Ack Arriaval(Packets)', axis =1)#O que se quer prever\n",
    "      base_completa = base_completa.drop('Last Router Ocupation Packet Sent(Packets)', axis =1)\n",
    "      base_completa = base_completa.drop('Network Situation', axis =1)\n",
    "      base_completa = base_completa.drop('AckArrival(ms)', axis =1)\n",
    "      base_completa = base_completa.drop('TSInsideAck(ms)', axis =1)\n",
    "      base_completa = base_completa.drop('RTTAck(ms)', axis =1)\n",
    "      entradas = base_completa[len(base_completa) - self.len_base_teste - (self.T+self.n_steps_out-1):].values\n",
    "      #base_teste_features = base_teste.iloc[:, [1,2,3,6]].values\n",
    "      #print(\"#############len(base_teste): \",len(self.base_teste))\n",
    "      \n",
    "      X_teste = []\n",
    "\n",
    "      for i in range(self.T+self.n_steps_out-1, self.len_base_teste+self.T+self.n_steps_out-1): # para as duzentas previsoes, o mesmo tramanho do Teste.csv, ou seja 290-90\n",
    "        #X_teste.append(entradas[i-self.T:i,0:4])\n",
    "        #end_ix = i+self.n_steps_out\n",
    "        if i >= entradas.shape[0]:\n",
    "          break;\n",
    "        X_teste.append(entradas[i-(self.T+self.n_steps_out-1):i-(self.n_steps_out-1),0:4])\n",
    "\n",
    "        #previsores.append(base_treinamento[i-self.T:i, 0:4])#o que é considerado é o limite superior do rante -1\n",
    "        #real_congestion.append(base_treinamento[(i-1)+self.n_steps_out,4])#\n",
    "        #print(\"Previsor\")\n",
    "        #print(X_teste[i-self.T])\n",
    "        #input(\"Exibido mais um previsor\")\n",
    "\n",
    "\n",
    "      test_vectors = np.array(X_teste) # equivalente ao X_teste\n",
    "      '''\n",
    "      print(\"Amostra Testadores\")      \n",
    "      print(test_vectors[0])\n",
    "      print(test_vectors[1])\n",
    "      print(test_vectors[2])\n",
    "      input(\"Amostra Previsores Exibidos acima\")\n",
    "      print(\"Real Congestion: \")\n",
    "      print(self.real_congestion_test)\n",
    "      input(\"exibidos os Congestionamentos Reais\")\n",
    "      '''\n",
    "\n",
    "      return test_vectors\n",
    "    '''   \n",
    "    def RefreshConfusionClientMatrix(self):\n",
    "      #confrontar resultados\n",
    "      self.confusionMatrizModelClient = np.full((2,2),random.randint(0,9))\n",
    "\n",
    "    def RefreshConfusionServerMatrix(self):\n",
    "      #confrontar resultados\n",
    "      self.confusionMatrizModelServer = np.full((2,2),random.randint(0,9))\n",
    "    '''       \n",
    "    #parTotalModels abrange todos os modelos, inclusive o do cliente, apesar de ser descartado\n",
    "    def ReceiveModelFromServer(self, parCandidateMatrix, parReturnededModels, parServerType):\n",
    "      print(\"Cliente \", self.id, \" Recebido Modelo do Servidor\")\n",
    "      serverModel=[]\n",
    "      self.total_model_received_form_server = parReturnededModels\n",
    "      self.last_server_type_sender = parServerType\n",
    "      print(\"parServerType: \",parServerType)\n",
    "      self.weightsServerModel.clear()\n",
    "      for i in range(0,parReturnededModels):\n",
    "        if (self.last_server_type_sender == \"AMA\"):\n",
    "          for e in parCandidateMatrix:\n",
    "            self.weightsServerModel.append(e)\n",
    "        elif (self.last_server_type_sender == \"INTERCHANGE\"):\n",
    "          for e in parCandidateMatrix[i]:\n",
    "              serverModel.append(e)\n",
    "          self.weightsServerModel.append(serverModel.copy())\n",
    "          serverModel.clear()\n",
    "  \n",
    "      \n",
    "    def SendModelToServer(self):\n",
    "      self.centralServ.ReceiveModelsFromClients(self.id)\n",
    "      print(\"Client\", self.id, \"Sending Model To Server\")\n",
    "    '''\n",
    "    def TreinarModelo(self):\n",
    "      print(\"Cliente \", self.id, \"treinando Modelo\")\n",
    "      time.sleep(random.randint(0,9))\n",
    "      self.RefreshConfusionClientMatrix()\n",
    "\n",
    "    '''\n",
    "\n",
    "   \n",
    "    def GetPrevision(self, parSave=0,parLoadTestFromFile=False): #evalueta indica que é uma avaliação do modelo recebido como parametro, no caso do servidor\n",
    "\n",
    "      #parSave se refere aos pesos e modelo salvos a no round parSave. Por\n",
    "      #isso só é usado se parLoadTestFromFile for True\n",
    "      test_vectors = self.LoadTestData(parLoadTestFromFile)# parLoadTestFromFile indica que é para pegar do test_client, \n",
    "                                                           #que, a princípio, veio de outro experimento\n",
    "\n",
    "      #print(\"Observe os testadores\")\n",
    "      #print(\"shape: \",test_vectors.shape)\n",
    "      #print(test_vectors)\n",
    "      #input(\"testadores exibidos\")\n",
    "\n",
    "      if(not parLoadTestFromFile):\n",
    "        regressor=self.GetModel()\n",
    "        regressor.set_weights(self.weightsClientModel)\n",
    "\n",
    "      else:\n",
    "        print(\"FromFile\")\n",
    "        regressor = self.GetModelFromFile(parSave)\n",
    "\n",
    "      \n",
    "\n",
    "      previsoes = regressor.predict(test_vectors)\n",
    "      #print(\"Observe as previsoes:\")\n",
    "      #print(previsoes)\n",
    "      #input(\"Observe as previsoes\")\n",
    "      self.latest_prevision = np.empty((previsoes.shape[0],1))      \n",
    "      for i in range(previsoes.shape[0]):\n",
    "        self.latest_prevision[i][0]=previsoes[i][self.n_steps_out-1]\n",
    "      \n",
    "      '''\n",
    "      A ideia do laço a seguir é tomar a última posição dos vetores previstos pela rede neural, que corresponde a \n",
    "      n_steps_out no futuro.\n",
    "      latest_prevision = np.empty((previsoes.shape[0],1))\n",
    "      \n",
    "      for i in range(previsoes.shape[0]):\n",
    "        latest_prevision[i][0]=previsoes[i][self.n_steps_out-1]\n",
    "      '''\n",
    "      #self.mean_predicted_congestion = previsoes.mean();\n",
    "      #print(\"====== Média dos Congestionamentos Previstos Internamente: \",self.mean_predicted_congestion)\n",
    "      #print(\"Observe as previsoes mais remotas:\")\n",
    "      #print(latest_prevision)\n",
    "      #input(\"As previsões Remotas foram obtidas corretamente?\")\n",
    "      \n",
    "      \n",
    "      #Esperar dominar as previsões a frente\n",
    "      #previsoes.mean()\n",
    "      #self.real_congestion_test.mean()\n",
    "      #ion() # enables interactive mode \n",
    " \n",
    "      \n",
    "    \n",
    "      \n",
    "      #input(\"Observe a tendência\")\n",
    "      #print(\"Observe as previsoes\")\n",
    "      #print(\"shape: \",previsoes.shape)\n",
    "      #print(previsoes)\n",
    "      #pausa=input(\"previsoes Tabuladas\")\n",
    "     \n",
    "      #previsoes = parNeuralModel.predict(self.test_vectors)\n",
    "     \n",
    "   \n",
    "      #Observe que os previsores teste tem 90 quádruplas que conduzem ao resultado\n",
    "      #do último estado, da quádrupla 90. Prontamente preparado para pevisões....\n",
    "      \n",
    "      #classe_teste2 = np.array([])\n",
    "      #previsoes2 =  np.array([])\n",
    "      #classe_teste2,previsoes2 = self.GetMapedMatrix(previsoes) \n",
    "      #self.currentConfusionMatriz = confusion_matrix(classe_teste2,previsoes2) \n",
    "      \n",
    "      #return self.currentConfusionMatriz # Com a configuração corrente, essa é a matriz....\n",
    "      return previsoes\n",
    "        \n",
    "    def PlotResults(self,parLoadFromFile=False):\n",
    "      fig, graph = plt.subplots()\n",
    "      graph.plot(self.real_congestion_test, color = 'red', label = 'Cng Real')\n",
    "      #if(parLoadFromFile):\n",
    "        #graph.plot(self.latest_prevision*3.5, color = 'blue', label = 'Cng Previsto')\n",
    "      #else:\n",
    "      graph.plot(self.latest_prevision, color = 'blue', label = 'Cng Previsto')\n",
    "      graph.set_xlabel('ACK')\n",
    "      graph.set_ylabel('Ocupacao Fila')\n",
    "      graph.title.set_text('Previsão do Congestionamento {:0>3}'.format(self.id))\n",
    "      #graph.legend()\n",
    "      textbox = '\\n'.join([\n",
    "                          'Units: '+str(self.exp_units),\n",
    "                          'Epochs: ' + str(self.exp_epoch),\n",
    "                          '',\n",
    "                          'Batch Size: '+str(self.exp_batch_size),\n",
    "                          'Features Before: ' +str(self.T),\n",
    "                          'Round Aheads: ' + str(self.n_steps_out),\n",
    "                          'Congestion Protocol '+self.congestion_protocol,\n",
    "                          'RTT to Router: ' + str(self.exp_RTT_to_router),\n",
    "                          '',\n",
    "                          '',\n",
    "                          '...',\n",
    "                          '...',\n",
    "                          '...',\n",
    "                          ])\n",
    "      \n",
    "      bbox = dict(boxstyle='square', facecolor='lavender', alpha=0.5)\n",
    "      fig.text(1.1,1,textbox,fontsize=10,transform=graph.transAxes, bbox=bbox, verticalalignment='top')\n",
    "      self.num_plot=self.num_plot+1\n",
    "      #tem que passar dpi=300, bbox_inches='tight' para salvar igual mostra! ver **https://problemsolvingwithpython.com/06-Plotting-with-Matplotlib/06.04-Saving-Plots/**\n",
    "      if(parLoadFromFile):\n",
    "        fig.savefig(self.exp_dir_out_from_file+\"/client{id:0>3}_{num_plot:0>3}\".format(id=self.id,num_plot=self.num_plot)+\".png\",dpi=300, bbox_inches='tight')\n",
    "      else:\n",
    "        fig.savefig(self.exp_dir_out_from_fit+\"/client{id:0>3}_{num_plot:0>3}\".format(id=self.id,num_plot=self.num_plot)+\".png\",dpi=300, bbox_inches='tight')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "      \n",
    "            \n",
    "\n",
    "    def ServerModelIsBetter(self):\n",
    "      '''\n",
    "      Observe, pelas duas linhas abaixo, que a avaliação do modelo do servidor federated é uma\n",
    "      fase independente das avaliações internas do cliente, uma vez que se utiliza um\n",
    "      modelo destino, que será incorporado ao servidor apenas se oferecer um resultado\n",
    "      melhor, quando comparada a última previsão interna do cliente.\n",
    "      '''\n",
    "      regressorServer = self.GetModel()\n",
    "      #regressorServer.set_weights(self.weightsServerModel)\n",
    "      return self.EvalueteServerModel(regressorServer)\n",
    "\n",
    "\n",
    "\n",
    "class Server_Federated():\n",
    "\n",
    "  def __init__(self):\n",
    "    self.clients = []\n",
    "    self.ReceivedModel = [False,False,False]\n",
    "    self.consolidateWeightMatrix = []\n",
    "    self.total_clients = 0;\n",
    "\n",
    "  def PrintRegistredClients(self):\n",
    "    print(\"Registring Clients\")\n",
    "    for x in self.clients:\n",
    "      print(\"Client \", x.id)\n",
    "  \n",
    "  def RegisterClient(self, parCliente):\n",
    "    parCliente.id_in_server = self.total_clients\n",
    "    self.clients.append(parCliente)\n",
    "    self.total_clients = self.total_clients+1\n",
    "    #print(\"Cliente \", parCliente.id, \" Regitrado com sucesso\")\n",
    "\n",
    "  '''\n",
    "  def ReceiveModelsFromClient(self, parId):\n",
    "   print(\"Recebido Modelos dos Cliente \", parId)    \n",
    "   self.ConsolideModels()\n",
    "\n",
    "  '''  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Server_FederatedAMA(Server_Federated):\n",
    "  '''\n",
    "  During the aggregation,\n",
    "  we first sum and average the neuron weights of each model. Then we store the\n",
    "  average value in the designated global model position. In the neural network\n",
    "  model, the same process is calculated for every neuron. After completing Al-\n",
    "  gorithm 2, the central server aggregated model is sent to all the clients for the\n",
    "  next learning phase\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    Server_Federated.__init__(self)\n",
    "\n",
    "  def ConsolidateModels(self):\n",
    "\n",
    "    numberClients = len(self.clients)\n",
    "    #lstTemp = []\n",
    "    #arrays_in_Layer=[]\n",
    "    #lst_arrays_in_Layer = []\n",
    "    #lst_consolidated_arrays_in_layer = [] #as camadas, composta por arraysconsolidados\n",
    "    #consolidated_arrays_in_layer = [] #arrays da camada\n",
    "    #consolidated_array = None\n",
    "    consolidated_model = []\n",
    "    clients_weighted_models = []\n",
    "    '''\n",
    "    #Cada weightsClientModel é uma lista de numpyarrays crua \"flatem\", isto é\n",
    "    se um modelo tem, por exemplo, 3 camadas e cada uma com dois arrays, o \n",
    "    weightsClientModel será uma lista de 6 numpy´s, com os dois primeiros vetores da \n",
    "    primeira camada no início, seguidos dos dois da segunta e, depois, os dois da terceira.\n",
    "    Nada de listas. É uma Listona de numpys\n",
    "    '''\n",
    "    for client in self.clients:\n",
    "        #print(client.weightsClientModel)\n",
    "        #input(\"pesos acima\")\n",
    "        clients_weighted_models.append(client.weightsClientModel)\n",
    "    \n",
    "    \n",
    "    #Criando a estrutura do Modelo\n",
    "    #for model in client_weighted_model:\n",
    "    for i in range(0,len (clients_weighted_models)):#Cada Clinte\n",
    "       for j in range (0, len(clients_weighted_models[i])):\n",
    "            if(i==0):\n",
    "                consolidated_model.append(clients_weighted_models[i][j])#alocando a lista com os pesos do primeiro modelo.\n",
    "            else:\n",
    "                consolidated_model[j] = consolidated_model[j] + clients_weighted_models[i][j]\n",
    "            if (i == numberClients - 1):\n",
    "                consolidated_model[j] = consolidated_model[j]/numberClients\n",
    " \n",
    "    #self.consolidateWeightMatrix = consolidated_model # cuidado com isso!\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    for e in consolidated_model:\n",
    "        self.consolidateWeightMatrix.append(e)\n",
    "\n",
    "    \n",
    "    print(\"Amostra Peso Clientes:\")\n",
    "    for client in self.clients:\n",
    "      print(\"============================\")\n",
    "      print(client.weightsClientModel[0][0][0:4])\n",
    "    print(\"Amostra Peso Consolidado: \")\n",
    "    print(self.consolidateWeightMatrix[0][0][0:4])\n",
    "  \n",
    "  def FeedBackConsolidatedModel(self):\n",
    "    for x in self.clients:\n",
    "      x.ReceiveModelFromServer(self.consolidateWeightMatrix.copy(),1,\"AMA\")\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    print(\"Feedbacks Enviados e descartados\")\n",
    "\n",
    "\n",
    "\n",
    "class Server_FederatedInterChange(Server_Federated):\n",
    "  '''\n",
    "  Manda os modelos dos outros clientes para cada um dos clientes cadastrados \n",
    "  '''\n",
    "  def __init__(self):\n",
    "    Server_Federated.__init__(self)\n",
    "\n",
    "  def ConsolidateModels(self): # no interchance deve-se passar o  cliente, \n",
    "                                          # justamente para que o própio modelo não seja passado\n",
    "\n",
    "    #numberClients = len(self.clients)\n",
    "    #lstTemp = []\n",
    "    #arrays_in_Layer=[]\n",
    "    #lst_arrays_in_Layer = []\n",
    "    #lst_consolidated_arrays_in_layer = [] #as camadas, composta por arraysconsolidados\n",
    "    #consolidated_arrays_in_layer = [] #arrays da camada\n",
    "    #consolidated_array = None\n",
    "    clients_weighted_models = []\n",
    "    '''\n",
    "    #Cada weightsClientModel é uma lista de numpyarrays crua \"flatem\", isto é\n",
    "    se um modelo tem, por exemplo, 3 camadas e cada uma com dois arrays, o \n",
    "    weightsClientModel será uma lista de 6 numpy´s, com os dois primeiros vetores da \n",
    "    primeira camada no início, seguidos dos dois da segunta e, depois, os dois da terceira.\n",
    "    Nada de listas. É uma Listona de numpys\n",
    "    '''\n",
    "    for client in self.clients:\n",
    "        #print(client.weightsClientModel)\n",
    "        #input(\"pesos acima\")\n",
    "        clients_weighted_models.append(client.weightsClientModel)\n",
    "    \n",
    "    \n",
    "    #Criando a estrutura do Modelo\n",
    "    #for model in client_weighted_model:\n",
    "    client_model=[]\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    for i in range(0,len (clients_weighted_models)):#Cada Clinte\n",
    "      for j in range (0, len(clients_weighted_models[i])):\n",
    "        client_model.append(clients_weighted_models[i][j])\n",
    "      self.consolidateWeightMatrix.append(client_model.copy())\n",
    "      client_model.clear()\n",
    "  \n",
    " \n",
    "    #self.consolidateWeightMatrix = consolidated_model # cuidado com isso!\n",
    "    print(\"Amostra Peso Clientes:\")\n",
    "    for client in self.clients:\n",
    "      print(f\"========Cliente {client.id}=============\")\n",
    "      print(client.weightsClientModel[0][0][0:4])\n",
    "    print(\"Amostra Peso Consolidado por INTERCHANGE: \")\n",
    "    print(self.consolidateWeightMatrix[0][0][0][0:4])\n",
    "\n",
    "  def FeedBackConsolidatedModel(self):\n",
    "    consolidateWeightMatrix_to_client=[]\n",
    "    for x in self.clients:\n",
    "      for i in range (len(self.consolidateWeightMatrix)):\n",
    "         if(i != x.id_in_server):\n",
    "           consolidateWeightMatrix_to_client.append(self.consolidateWeightMatrix[i])\n",
    "      x.ReceiveModelFromServer(consolidateWeightMatrix_to_client.copy(),len(consolidateWeightMatrix_to_client),\"INTERCHANGE\")\n",
    "      consolidateWeightMatrix_to_client.clear()\n",
    "    self.consolidateWeightMatrix.clear()\n",
    "    print(\"Feedbacks Enviados e descartados\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b8e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.ma.core import exp\n",
    "'''\n",
    "Server::ConsolidateModels----------------Server::FeedBackConsolidatedModel--------------Client::RefreshModel\n",
    "'''\n",
    "\n",
    "#numClients = 3; #Can be gotten from user\n",
    "\n",
    "#lstClients = [];\n",
    "\n",
    "def GeneralTraining(parExpDir, parTrainingPath, parTestPath,parExpDescription):\n",
    "\n",
    "    objServeAMA = Server_FederatedAMA()\n",
    "    objServerInterChange = Server_FederatedInterChange()\n",
    "\n",
    "    #for i in range (numClients):\n",
    "      #objClient = Client(objServe,i)\n",
    "      #lstClients.append(objClient)\n",
    "\n",
    "    #for x in lstClients:\n",
    "      #print(\"Cliente \", x.id, \"Criado com Sucesso\");\n",
    "\n",
    "\n",
    "    #for x in lstClients:\n",
    "     #objServe.RegisterClient(x)\n",
    "\n",
    "    #objServe.PrintRegistredClients()\n",
    "\n",
    "    '''\n",
    "    for i in range (0,10):\n",
    "      print(\"==================Rodada \",i\" ========================\")\n",
    "      for x in lstClients:\n",
    "        x.TreinarModelo\n",
    "      for x in lstClients:\n",
    "        x.SendModelToServer\n",
    "      objServe.ConsolidateModels\n",
    "      objServe.FeedBackConsolidatedModel()\n",
    "      for x in lstClients:\n",
    "        x.AtualizarModelo();\n",
    "    '''\n",
    "\n",
    "    local_env=True;\n",
    "    exp_time=time.ctime();\n",
    "\n",
    "    exp_time = exp_time.replace(\":\", \"_\" )\n",
    "    exp_time = exp_time.replace(\" \", \"_\" )\n",
    "    '''\n",
    "    if(not local_env):\n",
    "      exp_dir = \"/content/drive/MyDrive/Colab Notebooks/Exp_000007/\"\n",
    "    else:\n",
    "      exp_dir = \"./Exp_000007/\"\n",
    "    '''\n",
    "    exp_dir=os.path.join(parExpDir, exp_time)\n",
    "    exp_dir_out_from_fit = exp_dir+\"/from_fit\" #para armazenar saídas obtidas de pesos/modelos treinados (fit)\n",
    "    exp_dir_out_from_file = exp_dir+\"/from_fle\" #para armazenar saídas obtidas de pesos/modelos recuperados do arquivo \n",
    "    #criando efetivamednte os diretórios\n",
    "    os.mkdir(exp_dir)\n",
    "    os.mkdir(exp_dir_out_from_fit)\n",
    "    os.mkdir(exp_dir_out_from_file)\n",
    "\n",
    "\n",
    "\n",
    "    exp_epoch = 50\n",
    "    exp_units = 100\n",
    "    exp_batch_size=1\n",
    "    exp_T=30\n",
    "    exp_steps_out =5\n",
    "    exp_congestion_protocol = \"BBR\"\n",
    "    exp_web_nodes= 2\n",
    "\n",
    "    #Registando dados gerais, comum a todos os clientes, no readme.txt\n",
    "\n",
    "    file_path = exp_dir+\"/readme.txt\"\n",
    "\n",
    "    f = open(file_path, \"w\")\n",
    "\n",
    "    f.write(\"Epocas: \"+ str(exp_epoch)+\"\\n\")\n",
    "    f.write(\"Units: \" +str(exp_units)+\"\\n\")\n",
    "    f.write(\"Batch Size:\" + str(exp_batch_size)+\"\\n\")\n",
    "    f.write(\"Janela Previsao: \"+ str(exp_T)+\"\\n\")\n",
    "    f.write(\"Ahead Steps:\"+str(exp_steps_out)+\"\\n\")\n",
    "    f.write(parExpDescription)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "    client01_id=0\n",
    "    '''\n",
    "    if(not local_env):\n",
    "      client01_training_path= \"/content/drive/MyDrive/Colab Notebooks/Exp_000007/training_client01.csv\"\n",
    "      client01_test_path = \"/content/drive/MyDrive/Colab Notebooks/Exp_000007/test_client01.csv\"\n",
    "    else:\n",
    "      client01_training_path= \"./Exp_000007/training_client01.csv\"\n",
    "      client01_test_path = \"./Exp_000007/test_client01.csv\"\n",
    "    '''\n",
    "    client01_training_path = parTrainingPath\n",
    "    client01_test_path = parTestPath\n",
    "    \n",
    "    client01_epoch = exp_epoch\n",
    "    client01_units = exp_units;\n",
    "    client01_batch_size=exp_batch_size\n",
    "    client01_T=exp_T\n",
    "    client01_steps_out = exp_steps_out\n",
    "    client01_congestion_protocol = exp_congestion_protocol\n",
    "    client01_web_nodes= exp_web_nodes\n",
    "    client01_RTT_router = \"50ms\"\n",
    "\n",
    "\n",
    "    #Registando dados relativos ao cliente 0, comum a todos os clientes, no readme_cliente_000.txt\n",
    "\n",
    "    file_path = exp_dir+\"/readme{:0>3}\"+\".txt\"\n",
    "\n",
    "    f = open(file_path.format(client01_id), \"w\")\n",
    "\n",
    "    f.write(str(client01_RTT_router))\n",
    "    f.close()\n",
    "\n",
    "    objClient1 = Client(client01_id,\n",
    "                        client01_training_path,\n",
    "                        client01_test_path, \n",
    "                        client01_epoch,\n",
    "                        client01_units,\n",
    "                        client01_batch_size,\n",
    "                        client01_T,\n",
    "                        client01_steps_out,\n",
    "                        client01_congestion_protocol,\n",
    "                        client01_web_nodes,\n",
    "                        client01_RTT_router,\n",
    "                        exp_time,\n",
    "                        exp_dir,\n",
    "                        exp_dir_out_from_fit,\n",
    "                        exp_dir_out_from_file)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    client02_id=1\n",
    "    client02_training_path='/content/drive/MyDrive/Colab Notebooks/Exp_000007/training_client02.csv'\n",
    "    client02_test_path =  '/content/drive/MyDrive/Colab Notebooks/Exp_000007/test_client02.csv'\n",
    "    client02_epoch = exp_epoch\n",
    "    client02_units = exp_units;\n",
    "    client02_batch_size=exp_batch_size\n",
    "    client02_T=exp_T\n",
    "    client02_steps_out =exp_steps_out\n",
    "    client02_congestion_protocol=exp_congestion_protocol\n",
    "    client02_web_nodes= exp_web_nodes\n",
    "    client02_RTT_router = \"341.99769e-01ms\"\n",
    "\n",
    "    file_path = exp_dir+\"/readme{:0>3}\"+\".txt\"\n",
    "\n",
    "    f = open(file_path.format(client02_id), \"w\")\n",
    "\n",
    "    f.write(str(client02_RTT_router))\n",
    "    f.close()\n",
    "\n",
    "    objClient2 = Client(client02_id,\n",
    "                        client02_training_path,\n",
    "                        client02_test_path, \n",
    "                        client02_epoch,\n",
    "                        client02_units,\n",
    "                        client02_batch_size,\n",
    "                        client02_T,\n",
    "                        client02_steps_out,\n",
    "                        client02_congestion_protocol,\n",
    "                        client02_web_nodes,\n",
    "                        client02_RTT_router,\n",
    "                        exp_time,\n",
    "                        exp_dir,\n",
    "                        exp_dir_out_from_fit,\n",
    "                        exp_dir_out_from_file)\n",
    "    \n",
    "    objClient3 = Client(2,'/content/drive/MyDrive/Colab Notebooks/Exp_000002/training_client03_10_1_2_2to10_35_0_2_trainingFri Feb 24 10_09_37.csv',\n",
    "                                   '/content/drive/MyDrive/Colab Notebooks/Exp_000002/test_Fri Feb 24 09_39_49.csv', 90);\n",
    "\n",
    "    \n",
    "    #########################Registrando no Servidor Central#######################################\n",
    "\n",
    "    objServeAMA.RegisterClient(objClient1) #Refresh é atualização por trinamento\n",
    "    objServeAMA.RegisterClient(objClient2)\n",
    "    objServerInterChange.RegisterClient(objClient1) #Refresh é atualização por trinamento\n",
    "    objServerInterChange.RegisterClient(objClient2)\n",
    "    #objServe.RegisterClient(objClient3)\n",
    "\n",
    "    #########################Atualizando o modelo por treinamento e Consolidação do Servidor#######################################\n",
    "\n",
    "    '''\n",
    "    for i in range(2):\n",
    "      print(\"##################Round \", i, \" ##################################\")\n",
    "      #########################Atualizando o modelo por treinamento #######################################\n",
    "      #Observe que isso pode ser feito por treinamento ou por consolidação\n",
    "      #Quando feito por treinamento, os pesos são sempre atualizados no final do treinamento\n",
    "      #Já na consolidação, vai depender se houve um melhor resultado (média avsoluta dos erros)\n",
    "      objClient1.RefreshModel(parInitial=True) #Refresh por Treinamento\n",
    "      #gc.collect()\n",
    "      #objClient2.RefreshModel(parInitial=True)\n",
    "      #gc.collect()\n",
    "\n",
    "      #objClient3.RefreshModel(parInitial=True)\n",
    "      #gc.collect()\n",
    "\n",
    "\n",
    "      ###################Testando#################################\n",
    "\n",
    "\n",
    "      objClient1.GetPrevision()\n",
    "      objClient1.PlotResults();\n",
    "\n",
    "      ###################Pelo Arquivo#################################\n",
    "\n",
    "      #objClient1.RefreshModelFromFile(i)\n",
    "      #objClient1.GetPrevision(i,parLoadTestFromFile=True)\n",
    "      #objClient1.PlotResults(parLoadFromFile=True)\n",
    "      #objClient2.GetPrevision()\n",
    "      #objClient2.PlotResults()\n",
    "      '''\n",
    "      objClient3.GetPrevision()\n",
    "\n",
    "      '''\n",
    "      #########################Consolidando os modelos AMA#######################################\n",
    "\n",
    "      #objServeAMA.ConsolidateModels() \n",
    "      #objServeAMA.FeedBackConsolidatedModel() #Joga para os clientes o Modelo AMA\n",
    "\n",
    "      #########################Testando o novo modelo AMA#######################################\n",
    "      #########################Atualizando, conforme o caso#######################################\n",
    "       #########################Novas aproximações, após atualização ou não dos modelos#######################################\n",
    "\n",
    "      #if(objClient1.RefreshFromServerModel()): # Atualização considerando o modelo do servidor e não por treinamento, conforme o método RefreshModel\n",
    "        #objClient1.GetPrevision() #Só obtem uma nova previsão e printa, se houve atualização, justamente para comparar\n",
    "        #objClient1.PlotResults();\n",
    "      #if(objClient2.RefreshFromServerModel()):\n",
    "        #objClient2.GetPrevision()\n",
    "        #objClient2.PlotResults();\n",
    "      #objClient3.RefreshModel()\n",
    "      #print (objClient3.currentConfusionMatriz)\n",
    "\n",
    "        #########################Consolidando os modelos Interchange#######################################\n",
    "\n",
    "      #objServerInterChange.ConsolidateModels() \n",
    "      #objServerInterChange.FeedBackConsolidatedModel() #Joga para os clientes o Modelo Interchange\n",
    "\n",
    "      #########################Testando o novo modelo Interchange#######################################\n",
    "      #########################Atualizando, conforme o caso#######################################\n",
    "      #########################Novas aproximações, após atualização ou não dos modelos#######################################\n",
    "      #if(objClient1.RefreshFromServerModel()): # Atualização considerando o modelo do servidor e não por treinamento, conforme o método RefreshModel\n",
    "        #objClient1.GetPrevision()\n",
    "        #objClient1.PlotResults();\n",
    "      #if(objClient2.RefreshFromServerModel()):\n",
    "        #objClient2.GetPrevision()\n",
    "        #objClient2.PlotResults();\n",
    "      #objClient3.RefreshModel()\n",
    "      #print (objClient3.currentConfusionMatriz)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #objClient3.GetPrevision()\n",
    "      #print (objClient3.currentConfusionMatriz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa6c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliar um modelo, treinado em uma determinada topologia\n",
    "#em uma outra parPathTestFromAnotherTopology\n",
    "def EvalueteModelLevarage(parPreviousExpTime,\n",
    "                          parPreviousTrainingExpDir, \n",
    "                          parPreviousTrainingPath, \n",
    "                          parPathTestFromAnotherTopology, \n",
    "                          parExpDescription):\n",
    "    \n",
    "    local_env=True;\n",
    "    exp_time=parPreviousExpTime\n",
    "    #exp_time=time.ctime();\n",
    "\n",
    "    #exp_time = exp_time.replace(\":\", \"_\" )\n",
    "    #exp_time = exp_time.replace(\" \", \"_\" )\n",
    "    '''\n",
    "    if(not local_env):\n",
    "      exp_dir = \"/content/drive/MyDrive/Colab Notebooks/Exp_000007/\"\n",
    "    else:\n",
    "      exp_dir = \"./Exp_000007/\"\n",
    "    '''\n",
    "    exp_dir=parPreviousTrainingExpDir\n",
    "    exp_dir_out_from_fit = exp_dir+\"/from_fit\" #para armazenar saídas obtidas de pesos/modelos treinados (fit)\n",
    "    exp_dir_out_from_file = exp_dir+\"/from_fle\" #para armazenar saídas obtidas de pesos/modelos recuperados do arquivo \n",
    "    #criando efetivamednte os diretórios\n",
    "    #Não precisa criar os diretórios, pois, a princípio já existem\n",
    "\n",
    "\n",
    "    exp_epoch = 50\n",
    "    exp_units = 100\n",
    "    exp_batch_size=1\n",
    "    exp_T=30\n",
    "    exp_steps_out =5\n",
    "    exp_congestion_protocol = \"BBR\"\n",
    "    exp_web_nodes= 2\n",
    "    \n",
    "    file_path = exp_dir+\"/readme.txt\"\n",
    "\n",
    "    f = open(file_path, \"a\")\n",
    "\n",
    "    f.write(\"Teste de Aderencia: \\n\")\n",
    "    f.write(parExpDescription)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    \n",
    "    client01_id=0\n",
    "    client01_training_path = parPreviousTrainingExpDir\n",
    "    client01_test_path = parPathTestFromAnotherTopology\n",
    "    \n",
    "    client01_epoch = exp_epoch\n",
    "    client01_units = exp_units;\n",
    "    client01_batch_size=exp_batch_size\n",
    "    client01_T=exp_T\n",
    "    client01_steps_out = exp_steps_out\n",
    "    client01_congestion_protocol = exp_congestion_protocol\n",
    "    client01_web_nodes= exp_web_nodes\n",
    "    client01_RTT_router = \"50ms\"\n",
    "\n",
    "\n",
    "    #Registando dados relativos ao cliente 0, comum a todos os clientes, no readme_cliente_000.txt\n",
    "\n",
    "    objClient1 = Client(client01_id,\n",
    "                        client01_training_path,\n",
    "                        client01_test_path, \n",
    "                        client01_epoch,\n",
    "                        client01_units,\n",
    "                        client01_batch_size,\n",
    "                        client01_T,\n",
    "                        client01_steps_out,\n",
    "                        client01_congestion_protocol,\n",
    "                        client01_web_nodes,\n",
    "                        client01_RTT_router,\n",
    "                        exp_time,\n",
    "                        exp_dir,\n",
    "                        exp_dir_out_from_fit,\n",
    "                        exp_dir_out_from_file)\n",
    "\n",
    "    lastRound=1\n",
    "\n",
    "    objClient1.GetPrevision(lastRound,parLoadTestFromFile=True)\n",
    "    objClient1.PlotResults(parLoadFromFile=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6ea2c",
   "metadata": {},
   "source": [
    "# Terminais: 40, 20 longos (4GB), 10 \"Very Short\" (10KB) e 10 \"Short\" (100KB), entrando no terço final da simulação.  \n",
    "# Topologia: Dumbell (1000MB,1MB de bottleneck), Terminal base 10ms; servidor 100ms;  RTT1=100ms, Salto RTT= 50ms. \n",
    "# Tempo de Simulação: 60min.\n",
    "\n",
    "\n",
    "Com o newReno, o terminal base não foi estrangulado. Parece ser mais estável na alocação de banda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Terminais: 40, 20 longos (4GB), 10 Very Short (10KB) e 10 Short (100KB), entrando no terço final da simulação.  \"+\"\\n\"  \n",
    "description =description + \"Topologia: Dumbell (1000MB,1MB de bottleneck), Terminal base 10ms; servidor 100ms;  RTT1=100ms, Salto RTT= 50ms. \\n\"\n",
    "description =description + \"Tempo de Simulação:60min.\\n\"\n",
    "description = description+ \"Não-longos para o terço final da simulação.\\n\"\n",
    "\n",
    "\n",
    "GeneralTraining(parExpDir=\"./Exp_0000012/\",\n",
    "                parTrainingPath=\"./Exp_0000012/training_client01.csv\",\n",
    "                parTestPath=\"./Exp_0000012/test_client01.csv\",\n",
    "                parExpDescription=description)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
